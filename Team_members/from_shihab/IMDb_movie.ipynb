{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07e3beca-168e-4c19-b7ef-f9b03015c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc0f145-2e1d-4d04-90a9-909a9cf1248e",
   "metadata": {},
   "source": [
    "# 1- Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb0de5-e9dc-4a46-b53b-c02f9c49d9d8",
   "metadata": {},
   "source": [
    "-IMDb Movie Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e4ec8d3-02d3-4017-b542-baeaa90adeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"Data/aclImdb\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0d8b32-9911-4f3a-ae74-f2156f2e149d",
   "metadata": {},
   "source": [
    "-Dataset contains 10,000 labeled movie reviews (positive/negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18e95cd7-2e7a-4f9e-b635-6c39dc89b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imdb_with_rating(base_dir, subset=\"train\", sample_size=5000):\n",
    "    rows = []\n",
    "    \n",
    "    for label_type in [\"pos\", \"neg\"]:\n",
    "        folder = os.path.join(base_dir, subset, label_type)\n",
    "        files = os.listdir(folder)\n",
    "        \n",
    "       \n",
    "        \n",
    "        sample_files = random.sample(files, sample_size)\n",
    "        \n",
    "        for fname in sample_files:\n",
    "            \n",
    "            file_id, rating_str = fname.split(\"_\")\n",
    "            rating = int(rating_str.split(\".\")[0]) \n",
    "            \n",
    "            with open(os.path.join(folder, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "            \n",
    "           \n",
    "            rows.append({\n",
    "                \"id\": int(file_id),\n",
    "                \"rating\": rating,\n",
    "                \"txt\": text,\n",
    "                \"label\": 1 if label_type == \"pos\" else 0\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ea40a9e-86b4-4d36-8a04-12775f0dd49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "      <th>txt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5903</td>\n",
       "      <td>8</td>\n",
       "      <td>I liked this movie sort of reminded me of my m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194</td>\n",
       "      <td>8</td>\n",
       "      <td>Perhaps the funniest 'backstage at Hollywood' ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5211</td>\n",
       "      <td>8</td>\n",
       "      <td>Since their nasty divorce from the Disney Comp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7176</td>\n",
       "      <td>10</td>\n",
       "      <td>OK - you want to test somebody on how comforta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5754</td>\n",
       "      <td>9</td>\n",
       "      <td>I remember seeing this one when I was seven or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  rating                                                txt  label\n",
       "0  5903       8  I liked this movie sort of reminded me of my m...      1\n",
       "1   194       8  Perhaps the funniest 'backstage at Hollywood' ...      1\n",
       "2  5211       8  Since their nasty divorce from the Disney Comp...      1\n",
       "3  7176      10  OK - you want to test somebody on how comforta...      1\n",
       "4  5754       9  I remember seeing this one when I was seven or...      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = load_imdb_with_rating(data_dir, subset=\"train\", sample_size=5000)\n",
    "\n",
    "print(\"Shape:\", df_sample.shape)\n",
    "df_sample.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0646ece-7ff3-4ca5-8a30-7332fe0f2a14",
   "metadata": {},
   "source": [
    "# 2- Cleaning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c2722-ff28-4192-851e-676a01e3d37a",
   "metadata": {},
   "source": [
    "-We need some libraries to start cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe3b91a3-61c0-45b8-8259-7ce4c0d08e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\bbuser\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Collecting joblib (from nltk)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.7.34-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\bbuser\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.8/1.5 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading regex-2025.7.34-cp312-cp312-win_amd64.whl (275 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, joblib, nltk\n",
      "Successfully installed joblib-1.5.1 nltk-3.9.1 regex-2025.7.34 tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\bbuser\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5343aec3-5313-4529-b54f-83d257fb2990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\python313\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\python313\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.7.34-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\python313\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading regex-2025.7.34-cp313-cp313-win_amd64.whl (275 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, nltk\n",
      "\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "   ---------------------------------------- 0/3 [tqdm]\n",
      "   ------------- -------------------------- 1/3 [regex]\n",
      "   ------------- -------------------------- 1/3 [regex]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   ---------------------------------------- 3/3 [nltk]\n",
      "\n",
      "Successfully installed nltk-3.9.1 regex-2025.7.34 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6f83e63-f4c2-4801-ac10-d387c6e30fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bbuser\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bbuser\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\bbuser\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fad09b-3690-4cea-ac56-010dde61d158",
   "metadata": {},
   "source": [
    "#### explanation for some language resources:\n",
    "##### download('stopwords') --> We use it to remove stopwords\n",
    "##### download('wordnet') --> Needed for lemmatization (reducing words to their base form)\n",
    "##### download('omw-1.4') --> Additional linguistic data that helps lemmatizer handle words better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33974eb0-9364-4ab1-b6de-8e32425dda56",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57e923b-bce4-4a5a-a129-60ef37b5e25f",
   "metadata": {},
   "source": [
    "### What is happening here?\n",
    "##### Loads the English stopword list from NLTK --> Converts it into a Python set for faster lookup\n",
    "##### Creates lemmatizer object from WordNet --> Lemmatization = reducing a word to its base "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88953fe7-3a23-45ab-92cd-6d9315d46825",
   "metadata": {},
   "source": [
    "# let's explain what we do for the cleaning step:\n",
    "##### Convert text to \"lowercase\"(1). Next, remove HTML tags using \"BeautifulSoup\"(2). After that remove \"urls\" and emails(3). Moving to, remove punctuation, numbers, emojis(4). Then we will spilt the sentences to the sprite words using \"tokenize\"(5). Moreover, remove \"stopwords\"(6).Before the final points, we will return the word to its origin using \"lemmatize\"(7). Finally, keep words longer than 2 chars(8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fce3ad6-5263-4057-b39b-4f86ae8f4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(text):\n",
    "    # 1. \n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. \n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    \n",
    "    # 3. \n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+|[\\w\\.-]+@[\\w\\.-]+', '', text)\n",
    "    \n",
    "    # 4. \n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # 5. \n",
    "    tokens = text.split()\n",
    "    \n",
    "    # 6. \n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    \n",
    "    # 7. \n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    \n",
    "    # 8. \n",
    "    tokens = [w for w in tokens if len(w) > 2]\n",
    "    \n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f72aa31-191c-4e76-85b7-fece9a197b6c",
   "metadata": {},
   "source": [
    "# 3- Apply Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c31c26a-6f8d-458b-ba6a-d3b63979c79d",
   "metadata": {},
   "source": [
    "- aAdd a new column cleaned_review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56d2d36a-7840-4a97-b21b-8858648dd6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample[\"cleaned_review\"] = df_sample[\"txt\"].apply(clean_review)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429f94a-0046-4436-94a5-ab320b4aeb2b",
   "metadata": {},
   "source": [
    "# 4- Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4aa05f32-5f3b-4a63-8109-a9a406306851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I liked this movie sort of reminded me of my m...</td>\n",
       "      <td>liked movie sort reminded marriage clean see f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perhaps the funniest 'backstage at Hollywood' ...</td>\n",
       "      <td>perhaps funniest backstage hollywood movie eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Since their nasty divorce from the Disney Comp...</td>\n",
       "      <td>since nasty divorce disney company disney keep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OK - you want to test somebody on how comforta...</td>\n",
       "      <td>want test somebody comfortable adolescence emb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I remember seeing this one when I was seven or...</td>\n",
       "      <td>remember seeing one seven eight must found cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>As an old white housewife I can still apprecia...</td>\n",
       "      <td>old white housewife still appreciate laurence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>James Cagney is best known for his tough chara...</td>\n",
       "      <td>james cagney best known tough character gangst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>If I could go back, even as an adult and reliv...</td>\n",
       "      <td>could back even adult relive day summer spent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This was a typical grade B movie in 1940s Holl...</td>\n",
       "      <td>typical grade movie hollywood yet succeeded wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Red Rock West is a perfect example of how good...</td>\n",
       "      <td>red rock west perfect example good film practi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 txt  \\\n",
       "0  I liked this movie sort of reminded me of my m...   \n",
       "1  Perhaps the funniest 'backstage at Hollywood' ...   \n",
       "2  Since their nasty divorce from the Disney Comp...   \n",
       "3  OK - you want to test somebody on how comforta...   \n",
       "4  I remember seeing this one when I was seven or...   \n",
       "5  As an old white housewife I can still apprecia...   \n",
       "6  James Cagney is best known for his tough chara...   \n",
       "7  If I could go back, even as an adult and reliv...   \n",
       "8  This was a typical grade B movie in 1940s Holl...   \n",
       "9  Red Rock West is a perfect example of how good...   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  liked movie sort reminded marriage clean see f...  \n",
       "1  perhaps funniest backstage hollywood movie eve...  \n",
       "2  since nasty divorce disney company disney keep...  \n",
       "3  want test somebody comfortable adolescence emb...  \n",
       "4  remember seeing one seven eight must found cha...  \n",
       "5  old white housewife still appreciate laurence ...  \n",
       "6  james cagney best known tough character gangst...  \n",
       "7  could back even adult relive day summer spent ...  \n",
       "8  typical grade movie hollywood yet succeeded wa...  \n",
       "9  red rock west perfect example good film practi...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[[\"txt\", \"cleaned_review\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b496655-13f6-41b8-953e-b1e2103d963b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "      <th>txt</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5903</td>\n",
       "      <td>8</td>\n",
       "      <td>I liked this movie sort of reminded me of my m...</td>\n",
       "      <td>1</td>\n",
       "      <td>liked movie sort reminded marriage clean see f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194</td>\n",
       "      <td>8</td>\n",
       "      <td>Perhaps the funniest 'backstage at Hollywood' ...</td>\n",
       "      <td>1</td>\n",
       "      <td>perhaps funniest backstage hollywood movie eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5211</td>\n",
       "      <td>8</td>\n",
       "      <td>Since their nasty divorce from the Disney Comp...</td>\n",
       "      <td>1</td>\n",
       "      <td>since nasty divorce disney company disney keep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7176</td>\n",
       "      <td>10</td>\n",
       "      <td>OK - you want to test somebody on how comforta...</td>\n",
       "      <td>1</td>\n",
       "      <td>want test somebody comfortable adolescence emb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5754</td>\n",
       "      <td>9</td>\n",
       "      <td>I remember seeing this one when I was seven or...</td>\n",
       "      <td>1</td>\n",
       "      <td>remember seeing one seven eight must found cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>12250</td>\n",
       "      <td>2</td>\n",
       "      <td>Upon viewing Tobe Hooper's gem, Crocodile, in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>upon viewing tobe hoopers gem crocodile develo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1686</td>\n",
       "      <td>1</td>\n",
       "      <td>Imagine that you are asked by your date what m...</td>\n",
       "      <td>0</td>\n",
       "      <td>imagine asked date movie wanted see remember s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>8252</td>\n",
       "      <td>3</td>\n",
       "      <td>Whattt was with the sound? It sounded like it ...</td>\n",
       "      <td>0</td>\n",
       "      <td>whattt sound sounded like dubbedotherwise bad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>6290</td>\n",
       "      <td>3</td>\n",
       "      <td>Recap: Ron is about to marry Mel. They are dee...</td>\n",
       "      <td>0</td>\n",
       "      <td>recap ron marry mel deeply love certain perfec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>3097</td>\n",
       "      <td>1</td>\n",
       "      <td>There can be no questions of spoilers for this...</td>\n",
       "      <td>0</td>\n",
       "      <td>question spoiler movie director beat spoiled m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  rating                                                txt  label  \\\n",
       "0      5903       8  I liked this movie sort of reminded me of my m...      1   \n",
       "1       194       8  Perhaps the funniest 'backstage at Hollywood' ...      1   \n",
       "2      5211       8  Since their nasty divorce from the Disney Comp...      1   \n",
       "3      7176      10  OK - you want to test somebody on how comforta...      1   \n",
       "4      5754       9  I remember seeing this one when I was seven or...      1   \n",
       "...     ...     ...                                                ...    ...   \n",
       "9995  12250       2  Upon viewing Tobe Hooper's gem, Crocodile, in ...      0   \n",
       "9996   1686       1  Imagine that you are asked by your date what m...      0   \n",
       "9997   8252       3  Whattt was with the sound? It sounded like it ...      0   \n",
       "9998   6290       3  Recap: Ron is about to marry Mel. They are dee...      0   \n",
       "9999   3097       1  There can be no questions of spoilers for this...      0   \n",
       "\n",
       "                                         cleaned_review  \n",
       "0     liked movie sort reminded marriage clean see f...  \n",
       "1     perhaps funniest backstage hollywood movie eve...  \n",
       "2     since nasty divorce disney company disney keep...  \n",
       "3     want test somebody comfortable adolescence emb...  \n",
       "4     remember seeing one seven eight must found cha...  \n",
       "...                                                 ...  \n",
       "9995  upon viewing tobe hoopers gem crocodile develo...  \n",
       "9996  imagine asked date movie wanted see remember s...  \n",
       "9997  whattt sound sounded like dubbedotherwise bad ...  \n",
       "9998  recap ron marry mel deeply love certain perfec...  \n",
       "9999  question spoiler movie director beat spoiled m...  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2766f4b-fd69-4863-99c4-0405899560f6",
   "metadata": {},
   "source": [
    "## Save a cleaned version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b17e8ed-3a4e-4c3c-b8b3-48c5db277c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_csv(\"imdb_cleaned_sample.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
