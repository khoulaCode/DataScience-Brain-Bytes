{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68bd18fc-ffb1-4a41-acd1-5e6b972b976d",
   "metadata": {},
   "source": [
    "## Sales Performance Analysis with Walmart Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f580184-fbd4-4ef5-9639-14d0c3ff7cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6019198-8680-4402-8d51-350ce2d9bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base path to your data folder\n",
    "path ='C:/Users/bbuser/Desktop/DataScience-Brain-Bytes/Team_members/from_alzahra/data/walmart-recruiting-store-sales-forecasting--'\n",
    "\n",
    "train = pd.read_csv(f\"{path}//train.csv\")\n",
    "features = pd.read_csv(f\"{path}//features.csv\")\n",
    "stores = pd.read_csv(f\"{path}//stores.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c97dcd2b-1e3f-4f5a-95d4-c74b503dc9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales Data:\n",
      "    Store  Dept        Date  Weekly_Sales  IsHoliday\n",
      "0      1     1  2010-02-05      24924.50      False\n",
      "1      1     1  2010-02-12      46039.49       True\n",
      "2      1     1  2010-02-19      41595.55      False\n",
      "3      1     1  2010-02-26      19403.54      False\n",
      "4      1     1  2010-03-05      21827.90      False\n",
      "Features Data:\n",
      "    Store        Date  Temperature  Fuel_Price  MarkDown1  MarkDown2  \\\n",
      "0      1  2010-02-05        42.31       2.572        NaN        NaN   \n",
      "1      1  2010-02-12        38.51       2.548        NaN        NaN   \n",
      "2      1  2010-02-19        39.93       2.514        NaN        NaN   \n",
      "3      1  2010-02-26        46.63       2.561        NaN        NaN   \n",
      "4      1  2010-03-05        46.50       2.625        NaN        NaN   \n",
      "\n",
      "   MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  \n",
      "0        NaN        NaN        NaN  211.096358         8.106      False  \n",
      "1        NaN        NaN        NaN  211.242170         8.106       True  \n",
      "2        NaN        NaN        NaN  211.289143         8.106      False  \n",
      "3        NaN        NaN        NaN  211.319643         8.106      False  \n",
      "4        NaN        NaN        NaN  211.350143         8.106      False  \n",
      "Stores Data:\n",
      "    Store Type    Size\n",
      "0      1    A  151315\n",
      "1      2    A  202307\n",
      "2      3    B   37392\n",
      "3      4    A  205863\n",
      "4      5    B   34875\n"
     ]
    }
   ],
   "source": [
    "# Optionally display the head of each DataFrame\n",
    "print(\"Sales Data:\\n\", train.head())\n",
    "print(\"Features Data:\\n\", features.head())\n",
    "print(\"Stores Data:\\n\", stores.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad479fe-8b7c-4de5-9e93-1bf9925ec6c7",
   "metadata": {},
   "source": [
    "#### Aggregation with groupby():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deb7e8d6-7604-46fa-b89c-ad189b7b7df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sales:\n",
      " Store\n",
      "1     2.224028e+08\n",
      "2     2.753824e+08\n",
      "3     5.758674e+07\n",
      "4     2.995440e+08\n",
      "5     4.547569e+07\n",
      "6     2.237561e+08\n",
      "7     8.159828e+07\n",
      "8     1.299512e+08\n",
      "9     7.778922e+07\n",
      "10    2.716177e+08\n",
      "11    1.939628e+08\n",
      "12    1.442872e+08\n",
      "13    2.865177e+08\n",
      "14    2.889999e+08\n",
      "15    8.913368e+07\n",
      "16    7.425243e+07\n",
      "17    1.277821e+08\n",
      "18    1.551147e+08\n",
      "19    2.066349e+08\n",
      "20    3.013978e+08\n",
      "21    1.081179e+08\n",
      "22    1.470756e+08\n",
      "23    1.987506e+08\n",
      "24    1.940160e+08\n",
      "25    1.010612e+08\n",
      "26    1.434164e+08\n",
      "27    2.538559e+08\n",
      "28    1.892637e+08\n",
      "29    7.714155e+07\n",
      "30    6.271689e+07\n",
      "31    1.996139e+08\n",
      "32    1.668192e+08\n",
      "33    3.716022e+07\n",
      "34    1.382498e+08\n",
      "35    1.315207e+08\n",
      "36    5.341221e+07\n",
      "37    7.420274e+07\n",
      "38    5.515963e+07\n",
      "39    2.074455e+08\n",
      "40    1.378703e+08\n",
      "41    1.813419e+08\n",
      "42    7.956575e+07\n",
      "43    9.056544e+07\n",
      "44    4.329309e+07\n",
      "45    1.123953e+08\n",
      "Name: Weekly_Sales, dtype: float64\n",
      "Average Sales:\n",
      " Dept\n",
      "1     19213.485088\n",
      "2     43607.020113\n",
      "3     11793.698516\n",
      "4     25974.630238\n",
      "5     21365.583515\n",
      "          ...     \n",
      "95    69824.423080\n",
      "96    15210.942761\n",
      "97    14255.576919\n",
      "98     6824.694889\n",
      "99      415.487065\n",
      "Name: Weekly_Sales, Length: 81, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Total sales per store\n",
    "total_sales_per_store = train.groupby(\"Store\")[\"Weekly_Sales\"].sum()\n",
    "\n",
    "# Average sales per department\n",
    "avg_sales_per_dept = train.groupby(\"Dept\")[\"Weekly_Sales\"].mean()\n",
    "\n",
    "print(\"Total Sales:\\n\", total_sales_per_store)\n",
    "print(\"Average Sales:\\n\", avg_sales_per_dept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9666f44-9f86-4ae0-aee5-934c66d0bf59",
   "metadata": {},
   "source": [
    "#### Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae63c6b2-929b-4009-813b-4817458819b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store  Dept        Date  Weekly_Sales  IsHoliday Type    Size\n",
      "0      1     1  2010-02-05      24924.50      False    A  151315\n",
      "1      1     1  2010-02-12      46039.49       True    A  151315\n",
      "2      1     1  2010-02-19      41595.55      False    A  151315\n",
      "3      1     1  2010-02-26      19403.54      False    A  151315\n",
      "4      1     1  2010-03-05      21827.90      False    A  151315\n"
     ]
    }
   ],
   "source": [
    "# Merge train with stores\n",
    "train_merged = pd.merge(train, stores, on=\"Store\", how=\"left\")\n",
    "print(train_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba49e65-6ff5-4bfc-b304-ee51df5446f4",
   "metadata": {},
   "source": [
    "#### Concatenating Weekly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08c9b84f-5601-4ec6-9c3c-38e5152eba73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (421570, 5)\n",
      "   Store  Dept       Date  Weekly_Sales  IsHoliday\n",
      "0      1     1 2010-02-05      24924.50      False\n",
      "1      1     1 2010-02-12      46039.49       True\n",
      "2      1     1 2010-02-19      41595.55      False\n",
      "3      1     1 2010-02-26      19403.54      False\n",
      "4      1     1 2010-03-05      21827.90      False\n"
     ]
    }
   ],
   "source": [
    "# Make sure 'Date' is treated as a datetime object\n",
    "train[\"Date\"] = pd.to_datetime(train[\"Date\"])\n",
    "\n",
    "# Split into two parts by date\n",
    "first_half = train[train[\"Date\"] < \"2011-01-01\"]\n",
    "second_half = train[train[\"Date\"] >= \"2011-01-01\"]\n",
    "\n",
    "# Concatenate both parts back together\n",
    "combined_data = pd.concat([first_half, second_half])\n",
    "\n",
    "# Optional: check shape and preview\n",
    "print(\"Combined shape:\", combined_data.shape)\n",
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b95cc53-2318-4f2c-a3ed-b6e4ab3bb1e9",
   "metadata": {},
   "source": [
    "#### Filtering and Frequency Counts (Using train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21f8a096-7fe9-434b-b670-be143536e3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Sales:\n",
      "    Store  Dept       Date  Weekly_Sales  IsHoliday\n",
      "0      1     1 2010-02-05      24924.50      False\n",
      "1      1     1 2010-02-12      46039.49       True\n",
      "2      1     1 2010-02-19      41595.55      False\n",
      "4      1     1 2010-03-05      21827.90      False\n",
      "5      1     1 2010-03-12      21043.39      False\n",
      "\n",
      "Store Frequencies:\n",
      " Store\n",
      "13    10474\n",
      "10    10315\n",
      "4     10272\n",
      "1     10244\n",
      "2     10238\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter rows with high sales (more than $20,000)\n",
    "high_sales = train[train[\"Weekly_Sales\"] > 20000]\n",
    "\n",
    "# Count number of records per store\n",
    "store_counts = train[\"Store\"].value_counts()\n",
    "\n",
    "# Optional: preview outputs\n",
    "print(\"High Sales:\\n\", high_sales.head())\n",
    "print(\"\\nStore Frequencies:\\n\", store_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153e445-12ee-4c09-a1fa-ec87ff0977d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
