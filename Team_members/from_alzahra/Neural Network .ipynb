{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b31f9549-70bf-47b7-8191-ac1f60fa1012",
   "metadata": {},
   "source": [
    "## Neural Network Regression with California Housing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59cdf45-d181-4ed8-b8b4-0197c67b6e01",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff4ba143-04cb-4e08-b2a1-878e432c17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734fc8e2-ef32-43fc-a252-78853584cf83",
   "metadata": {},
   "source": [
    "### Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac28b6f-389a-477e-bbbc-7de125f3e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load California Housing dataset\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split into train/validation/test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773fc161-7ecd-45b7-b354-8f7cd9f08f62",
   "metadata": {},
   "source": [
    "### Build Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c007cf8b-efa8-4871-a82c-07d7c63f09b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build a regression model\n",
    "def build_model(activation=\"relu\", optimizer=\"adam\"):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation=activation, input_shape=[X_train.shape[1]]),\n",
    "        layers.Dense(32, activation=activation),\n",
    "        layers.Dense(1, activation=\"linear\")  # Linear output for regression\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"mse\",   # Mean Squared Error\n",
    "        metrics=[\"mae\"]  # Mean Absolute Error\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dde487-e854-448f-97c9-86f98cdb420e",
   "metadata": {},
   "source": [
    "### Train Models with Different Optimizers + Report Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed00107b-900f-4b1e-93fc-7408d727e205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbuser\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.8872 - mae: 0.6489 - val_loss: 0.4669 - val_mae: 0.5040\n",
      "Epoch 2/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4089 - mae: 0.4551 - val_loss: 0.3980 - val_mae: 0.4505\n",
      "Epoch 3/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.3794 - mae: 0.4354 - val_loss: 0.3799 - val_mae: 0.4473\n",
      "Epoch 4/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3594 - mae: 0.4241 - val_loss: 0.3642 - val_mae: 0.4306\n",
      "Epoch 5/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3467 - mae: 0.4122 - val_loss: 0.3531 - val_mae: 0.4132\n",
      "Epoch 6/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.3302 - mae: 0.4028 - val_loss: 0.3445 - val_mae: 0.4024\n",
      "Epoch 7/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3294 - mae: 0.3980 - val_loss: 0.3449 - val_mae: 0.4124\n",
      "Epoch 8/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3153 - mae: 0.3929 - val_loss: 0.3313 - val_mae: 0.3982\n",
      "Epoch 9/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.3212 - mae: 0.3888 - val_loss: 0.3263 - val_mae: 0.3915\n",
      "Epoch 10/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3067 - mae: 0.3852 - val_loss: 0.3216 - val_mae: 0.3889\n",
      "Epoch 11/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.3037 - mae: 0.3809 - val_loss: 0.3227 - val_mae: 0.3933\n",
      "Epoch 12/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.2987 - mae: 0.3789 - val_loss: 0.3187 - val_mae: 0.3854\n",
      "Epoch 13/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.2958 - mae: 0.3761 - val_loss: 0.3089 - val_mae: 0.3794\n",
      "Epoch 14/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2964 - mae: 0.3744 - val_loss: 0.3109 - val_mae: 0.3861\n",
      "Epoch 15/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.2932 - mae: 0.3735 - val_loss: 0.3160 - val_mae: 0.3882\n",
      "Epoch 16/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.2886 - mae: 0.3708 - val_loss: 0.3149 - val_mae: 0.3937\n",
      "Epoch 17/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.2904 - mae: 0.3703 - val_loss: 0.3055 - val_mae: 0.3789\n",
      "Epoch 18/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2948 - mae: 0.3708 - val_loss: 0.3060 - val_mae: 0.3822\n",
      "Epoch 19/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.2821 - mae: 0.3668 - val_loss: 0.3024 - val_mae: 0.3729\n",
      "Epoch 20/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.2830 - mae: 0.3666 - val_loss: 0.3083 - val_mae: 0.3796\n",
      "Epoch 1/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.6896 - mae: 0.5906 - val_loss: 0.5158 - val_mae: 0.5388\n",
      "Epoch 2/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.4504 - mae: 0.4798 - val_loss: 0.4376 - val_mae: 0.4736\n",
      "Epoch 3/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.4146 - mae: 0.4578 - val_loss: 0.4185 - val_mae: 0.4585\n",
      "Epoch 4/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3987 - mae: 0.4467 - val_loss: 0.4343 - val_mae: 0.4525\n",
      "Epoch 5/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3827 - mae: 0.4359 - val_loss: 0.3957 - val_mae: 0.4474\n",
      "Epoch 6/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.3750 - mae: 0.4302 - val_loss: 0.4066 - val_mae: 0.4327\n",
      "Epoch 7/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3670 - mae: 0.4244 - val_loss: 0.3786 - val_mae: 0.4255\n",
      "Epoch 8/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3583 - mae: 0.4197 - val_loss: 0.3700 - val_mae: 0.4179\n",
      "Epoch 9/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3516 - mae: 0.4142 - val_loss: 0.3869 - val_mae: 0.4192\n",
      "Epoch 10/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3471 - mae: 0.4105 - val_loss: 0.3624 - val_mae: 0.4192\n",
      "Epoch 11/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3413 - mae: 0.4076 - val_loss: 0.3604 - val_mae: 0.4231\n",
      "Epoch 12/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3380 - mae: 0.4053 - val_loss: 0.3608 - val_mae: 0.4201\n",
      "Epoch 13/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3363 - mae: 0.4045 - val_loss: 0.3546 - val_mae: 0.4110\n",
      "Epoch 14/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3303 - mae: 0.4004 - val_loss: 0.3544 - val_mae: 0.4211\n",
      "Epoch 15/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3267 - mae: 0.3983 - val_loss: 0.3477 - val_mae: 0.4080\n",
      "Epoch 16/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3242 - mae: 0.3963 - val_loss: 0.3562 - val_mae: 0.4108\n",
      "Epoch 17/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3209 - mae: 0.3936 - val_loss: 0.3393 - val_mae: 0.4064\n",
      "Epoch 18/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3248 - mae: 0.3960 - val_loss: 0.3426 - val_mae: 0.4063\n",
      "Epoch 19/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3176 - mae: 0.3918 - val_loss: 0.3507 - val_mae: 0.4042\n",
      "Epoch 20/20\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3169 - mae: 0.3916 - val_loss: 0.3399 - val_mae: 0.3989\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3083 - mae: 0.3796 \n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3399 - mae: 0.3989 \n",
      "Adam Optimizer - MSE: 0.3083074986934662 MAE: 0.37964674830436707\n",
      "SGD Optimizer - MSE: 0.3398734927177429 MAE: 0.3989272713661194\n"
     ]
    }
   ],
   "source": [
    "# Train models with Adam and SGD\n",
    "model_adam = build_model(activation=\"relu\", optimizer=\"adam\")\n",
    "history_adam = model_adam.fit(X_train, y_train, epochs=20,\n",
    "                              validation_data=(X_val, y_val), verbose=1)\n",
    "# Try with SGD optimizer\n",
    "model_sgd = build_model(activation=\"relu\", optimizer=\"sgd\")\n",
    "history_sgd = model_sgd.fit(X_train, y_train, epochs=20,\n",
    "                            validation_data=(X_val, y_val), verbose=1)\n",
    "# Evaluate\n",
    "mse_adam, mae_adam = model_adam.evaluate(X_val, y_val)\n",
    "mse_sgd, mae_sgd = model_sgd.evaluate(X_val, y_val)\n",
    "print(\"Adam Optimizer - MSE:\", mse_adam, \"MAE:\", mae_adam)\n",
    "print(\"SGD Optimizer - MSE:\", mse_sgd, \"MAE:\", mae_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c763a3d1-6ff9-45a0-b8bb-2bca5cbbc7a0",
   "metadata": {},
   "source": [
    "## Task Is Done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d862216-835f-40fb-b5e0-c775dcf3a4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
