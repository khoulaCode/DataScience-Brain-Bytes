{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c28be0-bfe7-4f57-932c-28063590420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc4c6583-adc5-4158-8400-cb63fa155992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "      <th>txt</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6784</td>\n",
       "      <td>8</td>\n",
       "      <td>I like my Ronald Colman dashing and debonair, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>like ronald colman dashing debonair fellow see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11884</td>\n",
       "      <td>8</td>\n",
       "      <td>I found this film to be a fascinating study of...</td>\n",
       "      <td>1</td>\n",
       "      <td>found film fascinating study family crisis leo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1656</td>\n",
       "      <td>9</td>\n",
       "      <td>\"Thieves and Liars\" presents us with a very na...</td>\n",
       "      <td>1</td>\n",
       "      <td>thief liar present naturalistic depiction leve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4745</td>\n",
       "      <td>7</td>\n",
       "      <td>I can't understand why they decided to release...</td>\n",
       "      <td>1</td>\n",
       "      <td>cant understand decided release film introduce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>305</td>\n",
       "      <td>8</td>\n",
       "      <td>Screwball comedy about romantic mismatches in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>screwball comedy romantic mismatch new york ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2510</td>\n",
       "      <td>4</td>\n",
       "      <td>This TV film tells the story of extrovert Fran...</td>\n",
       "      <td>0</td>\n",
       "      <td>film tell story extrovert frannie suddenly ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>5041</td>\n",
       "      <td>2</td>\n",
       "      <td>Ye Lou's film Purple Butterfly pits a secret o...</td>\n",
       "      <td>0</td>\n",
       "      <td>lous film purple butterfly pit secret organiza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>8517</td>\n",
       "      <td>2</td>\n",
       "      <td>The biggest mystery of Veronica Mars is not on...</td>\n",
       "      <td>0</td>\n",
       "      <td>biggest mystery veronica mar one tackle screen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>5903</td>\n",
       "      <td>1</td>\n",
       "      <td>I live in Salt Lake City and I'm not a Mormon,...</td>\n",
       "      <td>0</td>\n",
       "      <td>live salt lake city mormon rent movie well liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>11429</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow probable the worst movie i have ever seen!...</td>\n",
       "      <td>0</td>\n",
       "      <td>wow probable worst movie ever seen person neve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  rating                                                txt  label  \\\n",
       "0      6784       8  I like my Ronald Colman dashing and debonair, ...      1   \n",
       "1     11884       8  I found this film to be a fascinating study of...      1   \n",
       "2      1656       9  \"Thieves and Liars\" presents us with a very na...      1   \n",
       "3      4745       7  I can't understand why they decided to release...      1   \n",
       "4       305       8  Screwball comedy about romantic mismatches in ...      1   \n",
       "...     ...     ...                                                ...    ...   \n",
       "9995   2510       4  This TV film tells the story of extrovert Fran...      0   \n",
       "9996   5041       2  Ye Lou's film Purple Butterfly pits a secret o...      0   \n",
       "9997   8517       2  The biggest mystery of Veronica Mars is not on...      0   \n",
       "9998   5903       1  I live in Salt Lake City and I'm not a Mormon,...      0   \n",
       "9999  11429       1  Wow probable the worst movie i have ever seen!...      0   \n",
       "\n",
       "                                         cleaned_review  \n",
       "0     like ronald colman dashing debonair fellow see...  \n",
       "1     found film fascinating study family crisis leo...  \n",
       "2     thief liar present naturalistic depiction leve...  \n",
       "3     cant understand decided release film introduce...  \n",
       "4     screwball comedy romantic mismatch new york ci...  \n",
       "...                                                 ...  \n",
       "9995  film tell story extrovert frannie suddenly ret...  \n",
       "9996  lous film purple butterfly pit secret organiza...  \n",
       "9997  biggest mystery veronica mar one tackle screen...  \n",
       "9998  live salt lake city mormon rent movie well liv...  \n",
       "9999  wow probable worst movie ever seen person neve...  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\bbuser\\Desktop\\DataScience-Brain-Bytes\\Team_members\\from_Hajer\\data\\imdb_cleaned_sample.csv\"\n",
    "df=pd.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0262dfd-7366-4f2f-9e92-225dfa6406a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'rating', 'txt', 'label', 'cleaned_review'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7030e3a7-4174-48ab-a485-b23087a23bdf",
   "metadata": {},
   "source": [
    "# **1.Features and Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "980e59ba-3ab4-4cbe-b2a1-0b0f1690cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"cleaned_review\"]\n",
    "y = df[\"label\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9d802be-91ef-42e0-8ae9-dad25d9a2946",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3241c88c-6d76-4345-ae65-cd703d21ce8d",
   "metadata": {},
   "source": [
    "# **2. Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0676c5a1-b8b8-4f60-a2a0-3a096248bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6265bb6-b091-4844-9ef1-95f6bd2a9b65",
   "metadata": {},
   "source": [
    "# **3. TF-IDF Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "253edb83-070b-47a4-b171-c30bebddfdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF vectorization complete.\n",
      "Number of features: 5000\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2), stop_words='english')\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF vectorization complete.\")\n",
    "print(f\"Number of features: {X_train_tfidf.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb114fc-0458-4592-b72a-7138416aefea",
   "metadata": {},
   "source": [
    "# **4. Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd141ea2-3b00-41f9-b2a0-dd835fdc23de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Logistic Regression =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      1000\n",
      "           1       0.84      0.85      0.84      1000\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.84      0.84      0.84      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n",
      "\n",
      "===== Decision Tree =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.67      1000\n",
      "           1       0.68      0.67      0.67      1000\n",
      "\n",
      "    accuracy                           0.67      2000\n",
      "   macro avg       0.67      0.67      0.67      2000\n",
      "weighted avg       0.67      0.67      0.67      2000\n",
      "\n",
      "\n",
      "===== Random Forest =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1000\n",
      "           1       0.82      0.79      0.80      1000\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.81      0.81      0.81      2000\n",
      "weighted avg       0.81      0.81      0.81      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "    # Evaluate\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, pos_label=1)\n",
    "    rec = recall_score(y_test, y_pred, pos_label=1)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1-score\": f1\n",
    "    })\n",
    "\n",
    "    # Print classification report\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950f5f5-085f-470c-908e-2aec68a60d4e",
   "metadata": {},
   "source": [
    "# **5. Results Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "654b0735-b8ce-4628-a943-6cb192925b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison Table:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.8415</td>\n",
       "      <td>0.836453</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.842680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.6735</td>\n",
       "      <td>0.675076</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.672024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.823899</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.804504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision  Recall  F1-score\n",
       "0  Logistic Regression    0.8415   0.836453   0.849  0.842680\n",
       "1        Decision Tree    0.6735   0.675076   0.669  0.672024\n",
       "2        Random Forest    0.8090   0.823899   0.786  0.804504"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nComparison Table:\\n\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f40d4-b37c-4eeb-9b6f-4a6bc4a4eb1e",
   "metadata": {},
   "source": [
    "Logistic Regression achieved the highest overall accuracy and F1-score, making it the best performer for this dataset.\n",
    "\n",
    "Random Forest performed reasonably well but slightly lower in recall.\n",
    "\n",
    "Decision Tree had the lowest performance across all metrics, likely due to overfitting on training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
