{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ca65e07-93b8-4dd0-8e2c-3d62e9a6b2b6",
   "metadata": {},
   "source": [
    "#### **As a Data Scientist, I want to clean and preprocess IMDb movie reviews,So that the text is standardized, noise-free, and ready for sentiment analysis.**\n",
    "\n",
    "    \n",
    "### **Acceptance Criteria**\n",
    "\n",
    "## **1. Dataset**\n",
    "\n",
    "1.1. Use the IMDb Movie Reviews Dataset:  \n",
    "\n",
    "1.2. Dataset contains 50,000 labeled movie reviews (positive/negative).\n",
    "\n",
    "1.3. Focus on the review text.\n",
    "\n",
    "## **2. Cleaning Steps**\n",
    "\n",
    "2.1. Convert text to lowercase.\n",
    "\n",
    "2.2. Remove HTML tags (many reviews contain < br > ).\n",
    "\n",
    "2.3. Remove URLs and email addresses.\n",
    "\n",
    "2.4. Remove punctuation, numbers, and emojis.\n",
    "\n",
    "2.5. Remove stopwords (NLTK/Spacy).\n",
    "\n",
    "2.6. Perform lemmatization (reduce words to their base form).\n",
    "\n",
    "2.7. Keep only meaningful tokens (length > 2).\n",
    "\n",
    "## **3. Deliverables**\n",
    "\n",
    "3.1. A cleaned dataset with original review and cleaned review text.\n",
    "\n",
    "3.2. A function clean_review(text) that applies the pipeline.\n",
    "\n",
    "3.3. At least 5 before/after cleaning examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff561de6-ef41-419c-956d-83cda7abdaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebddcf77-b177-4131-9c3b-d6ed13b80371",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"Data/aclImdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcc1fcd3-f47d-455a-82ac-6efa8f1e247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imdb_with_rating_v2(base_dir, subset=\"train\", sample_size=5000):\n",
    "    data_records = []\n",
    "\n",
    "    categories = {\"pos\": 1, \"neg\": 0}  # map labels to 1/0\n",
    "    \n",
    "    for label, label_value in categories.items():\n",
    "        path = os.path.join(base_dir, subset, label)\n",
    "        filenames = random.sample(os.listdir(path), sample_size)\n",
    "\n",
    "        for filename in filenames:\n",
    "            # filename looks like \"12345_7.txt\"\n",
    "            file_id, rating_str = filename.split(\"_\")\n",
    "            rating = int(rating_str.split(\".\")[0])  # extract rating number\n",
    "            \n",
    "            file_path = os.path.join(path, filename)\n",
    "            with open(file_path, encoding=\"utf-8\") as f:\n",
    "                review_text = f.read()\n",
    "            \n",
    "            data_records.append({\n",
    "                \"id\": int(file_id),\n",
    "                \"rating\": rating,\n",
    "                \"txt\": review_text,\n",
    "                \"label\": label_value\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(data_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ad19af7-3ae0-4648-aeae-114c4c0972ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "      <th>txt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6784</td>\n",
       "      <td>8</td>\n",
       "      <td>I like my Ronald Colman dashing and debonair, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11884</td>\n",
       "      <td>8</td>\n",
       "      <td>I found this film to be a fascinating study of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1656</td>\n",
       "      <td>9</td>\n",
       "      <td>\"Thieves and Liars\" presents us with a very na...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4745</td>\n",
       "      <td>7</td>\n",
       "      <td>I can't understand why they decided to release...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>305</td>\n",
       "      <td>8</td>\n",
       "      <td>Screwball comedy about romantic mismatches in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  rating                                                txt  label\n",
       "0   6784       8  I like my Ronald Colman dashing and debonair, ...      1\n",
       "1  11884       8  I found this film to be a fascinating study of...      1\n",
       "2   1656       9  \"Thieves and Liars\" presents us with a very na...      1\n",
       "3   4745       7  I can't understand why they decided to release...      1\n",
       "4    305       8  Screwball comedy about romantic mismatches in ...      1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset = load_imdb_with_rating_v2(data_dir, subset=\"train\", sample_size=5000)\n",
    "print(f\"Shape: {df_subset.shape}\")\n",
    "df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90022b18-7b07-4883-b1cb-364c49b1a2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\bbuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\bbuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\bbuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bbuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bbuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\bbuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa36357-ac13-44e4-baeb-abf2605331f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\bbuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\bbuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\bbuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bbuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bbuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\bbuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ca31f6f-f844-4598-ab5d-e71588390f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bbuser\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bbuser\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\bbuser\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ecccbe0-8287-4e17-b25a-7f5386b06c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9981691c-70d1-487f-97c2-ee806a870ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_review(review_text):\n",
    "    \"\"\"Clean and normalize raw review text.\"\"\"\n",
    "    \n",
    "    # Step A: lowercase\n",
    "    cleaned = review_text.lower()\n",
    "    \n",
    "    # Step B: strip HTML tags\n",
    "    cleaned = BeautifulSoup(cleaned, \"html.parser\").get_text()\n",
    "    \n",
    "    # Step C: remove URLs and emails\n",
    "    cleaned = re.sub(r'(http\\S+|www\\S+|https\\S+|[\\w\\.-]+@[\\w\\.-]+)', '', cleaned)\n",
    "    \n",
    "    # Step D: keep only alphabetic characters and spaces\n",
    "    cleaned = re.sub(r'[^a-z\\s]', '', cleaned)\n",
    "    \n",
    "    # Step E: tokenize\n",
    "    words = cleaned.split()\n",
    "    \n",
    "    # Step F: drop stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Step G: lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Step H: filter short tokens\n",
    "    words = [word for word in words if len(word) > 2]\n",
    "    \n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fce4afd4-92db-48a8-a48a-95e6a6bcb97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset[\"cleaned_review\"] = df_subset[\"txt\"].map(preprocess_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ce5bad3-7207-487d-931c-89475fad5d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like my Ronald Colman dashing and debonair, ...</td>\n",
       "      <td>like ronald colman dashing debonair fellow see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I found this film to be a fascinating study of...</td>\n",
       "      <td>found film fascinating study family crisis leo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Thieves and Liars\" presents us with a very na...</td>\n",
       "      <td>thief liar present naturalistic depiction leve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can't understand why they decided to release...</td>\n",
       "      <td>cant understand decided release film introduce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Screwball comedy about romantic mismatches in ...</td>\n",
       "      <td>screwball comedy romantic mismatch new york ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I finally purchased and added to my collection...</td>\n",
       "      <td>finally purchased added collection copy show p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I was 16 when I first saw the movie, and it ha...</td>\n",
       "      <td>first saw movie always huge favorite mine cour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>If you've ever seen the trailer for the film \"...</td>\n",
       "      <td>youve ever seen trailer film recruit colin far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>While the soundtrack is a bit dated, this stor...</td>\n",
       "      <td>soundtrack bit dated story relevant ever blue ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This movie completely ran laps around the orig...</td>\n",
       "      <td>movie completely ran lap around original dolem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 txt  \\\n",
       "0  I like my Ronald Colman dashing and debonair, ...   \n",
       "1  I found this film to be a fascinating study of...   \n",
       "2  \"Thieves and Liars\" presents us with a very na...   \n",
       "3  I can't understand why they decided to release...   \n",
       "4  Screwball comedy about romantic mismatches in ...   \n",
       "5  I finally purchased and added to my collection...   \n",
       "6  I was 16 when I first saw the movie, and it ha...   \n",
       "7  If you've ever seen the trailer for the film \"...   \n",
       "8  While the soundtrack is a bit dated, this stor...   \n",
       "9  This movie completely ran laps around the orig...   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  like ronald colman dashing debonair fellow see...  \n",
       "1  found film fascinating study family crisis leo...  \n",
       "2  thief liar present naturalistic depiction leve...  \n",
       "3  cant understand decided release film introduce...  \n",
       "4  screwball comedy romantic mismatch new york ci...  \n",
       "5  finally purchased added collection copy show p...  \n",
       "6  first saw movie always huge favorite mine cour...  \n",
       "7  youve ever seen trailer film recruit colin far...  \n",
       "8  soundtrack bit dated story relevant ever blue ...  \n",
       "9  movie completely ran lap around original dolem...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset.loc[:, [\"txt\", \"cleaned_review\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f782ccbd-b037-4a96-822c-48db718811b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "      <th>txt</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6784</td>\n",
       "      <td>8</td>\n",
       "      <td>I like my Ronald Colman dashing and debonair, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>like ronald colman dashing debonair fellow see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11884</td>\n",
       "      <td>8</td>\n",
       "      <td>I found this film to be a fascinating study of...</td>\n",
       "      <td>1</td>\n",
       "      <td>found film fascinating study family crisis leo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1656</td>\n",
       "      <td>9</td>\n",
       "      <td>\"Thieves and Liars\" presents us with a very na...</td>\n",
       "      <td>1</td>\n",
       "      <td>thief liar present naturalistic depiction leve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4745</td>\n",
       "      <td>7</td>\n",
       "      <td>I can't understand why they decided to release...</td>\n",
       "      <td>1</td>\n",
       "      <td>cant understand decided release film introduce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>305</td>\n",
       "      <td>8</td>\n",
       "      <td>Screwball comedy about romantic mismatches in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>screwball comedy romantic mismatch new york ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2510</td>\n",
       "      <td>4</td>\n",
       "      <td>This TV film tells the story of extrovert Fran...</td>\n",
       "      <td>0</td>\n",
       "      <td>film tell story extrovert frannie suddenly ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>5041</td>\n",
       "      <td>2</td>\n",
       "      <td>Ye Lou's film Purple Butterfly pits a secret o...</td>\n",
       "      <td>0</td>\n",
       "      <td>lous film purple butterfly pit secret organiza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>8517</td>\n",
       "      <td>2</td>\n",
       "      <td>The biggest mystery of Veronica Mars is not on...</td>\n",
       "      <td>0</td>\n",
       "      <td>biggest mystery veronica mar one tackle screen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>5903</td>\n",
       "      <td>1</td>\n",
       "      <td>I live in Salt Lake City and I'm not a Mormon,...</td>\n",
       "      <td>0</td>\n",
       "      <td>live salt lake city mormon rent movie well liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>11429</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow probable the worst movie i have ever seen!...</td>\n",
       "      <td>0</td>\n",
       "      <td>wow probable worst movie ever seen person neve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  rating                                                txt  label  \\\n",
       "0      6784       8  I like my Ronald Colman dashing and debonair, ...      1   \n",
       "1     11884       8  I found this film to be a fascinating study of...      1   \n",
       "2      1656       9  \"Thieves and Liars\" presents us with a very na...      1   \n",
       "3      4745       7  I can't understand why they decided to release...      1   \n",
       "4       305       8  Screwball comedy about romantic mismatches in ...      1   \n",
       "...     ...     ...                                                ...    ...   \n",
       "9995   2510       4  This TV film tells the story of extrovert Fran...      0   \n",
       "9996   5041       2  Ye Lou's film Purple Butterfly pits a secret o...      0   \n",
       "9997   8517       2  The biggest mystery of Veronica Mars is not on...      0   \n",
       "9998   5903       1  I live in Salt Lake City and I'm not a Mormon,...      0   \n",
       "9999  11429       1  Wow probable the worst movie i have ever seen!...      0   \n",
       "\n",
       "                                         cleaned_review  \n",
       "0     like ronald colman dashing debonair fellow see...  \n",
       "1     found film fascinating study family crisis leo...  \n",
       "2     thief liar present naturalistic depiction leve...  \n",
       "3     cant understand decided release film introduce...  \n",
       "4     screwball comedy romantic mismatch new york ci...  \n",
       "...                                                 ...  \n",
       "9995  film tell story extrovert frannie suddenly ret...  \n",
       "9996  lous film purple butterfly pit secret organiza...  \n",
       "9997  biggest mystery veronica mar one tackle screen...  \n",
       "9998  live salt lake city mormon rent movie well liv...  \n",
       "9999  wow probable worst movie ever seen person neve...  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4c1eac2-db81-4ca3-85c1-1beac868aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.to_csv(\"imdb_cleaned_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d150ff-d777-4905-9381-60ff783255c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
