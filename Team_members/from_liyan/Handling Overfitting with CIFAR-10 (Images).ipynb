{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55029b5c",
   "metadata": {},
   "source": [
    "# Handling Overfitting with CIFAR-10 (Images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bdde89",
   "metadata": {},
   "source": [
    "####  I want to train a feed-forward neural network (Dense Neural Network) on the CIFAR-10 dataset (small color images of 10 object classes), So that I can explore how regularization techniques (dropout, early stopping, weight decay) help reduce overfitting on more complex datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f44e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, math, random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1baa989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Reproducibility\n",
    "# ---------------------------\n",
    "SEED = 1337\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "OUTDIR = \"mlp_cifar10_runs\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 60  # long enough to see overfitting for baseline MLP\n",
    "VAL_SPLIT = 0.2\n",
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cf1c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Data\n",
    "# ---------------------------\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "num_classes = 10\n",
    "\n",
    "# Normalize to [0,1] and flatten for MLP\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test  = x_test.astype(\"float32\") / 255.0\n",
    "x_train = x_train.reshape((x_train.shape[0], -1))\n",
    "x_test  = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test  = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "input_dim = x_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdfdfae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Model builder\n",
    "# ---------------------------\n",
    "def build_mlp(\n",
    "    input_dim:int,\n",
    "    hidden_units=(512, 256),\n",
    "    dropout_rate:float=0.0,\n",
    "    l2_lambda:float=0.0,\n",
    "    use_batchnorm:bool=False,\n",
    "    num_classes:int=10,\n",
    "):\n",
    "    reg = regularizers.l2(l2_lambda) if l2_lambda and l2_lambda > 0 else None\n",
    "    inputs = keras.Input(shape=(input_dim,))\n",
    "    x = inputs\n",
    "    for i, hu in enumerate(hidden_units):\n",
    "        x = layers.Dense(hu, activation=None, kernel_regularizer=reg, name=f\"dense_{i}\")(x)\n",
    "        if use_batchnorm:\n",
    "            x = layers.BatchNormalization(name=f\"bn_{i}\")(x)\n",
    "        x = layers.ReLU(name=f\"relu_{i}\")(x)\n",
    "        if dropout_rate and dropout_rate > 0:\n",
    "            x = layers.Dropout(dropout_rate, name=f\"dropout_{i}\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"logits\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def compile_model(model, lr=LR):\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a42fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Training helper\n",
    "# ---------------------------\n",
    "def train_experiment(\n",
    "    run_name:str,\n",
    "    hidden_units=(512,256),\n",
    "    dropout_rate=0.0,\n",
    "    l2_lambda=0.0,\n",
    "    use_batchnorm=False,\n",
    "    use_early_stopping=False,\n",
    "    patience=8,\n",
    "    max_epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LR,\n",
    "):\n",
    "    print(f\"\\n=== RUN: {run_name} ===\")\n",
    "    print(json.dumps({\n",
    "        \"hidden_units\": hidden_units,\n",
    "        \"dropout_rate\": dropout_rate,\n",
    "        \"l2_lambda\": l2_lambda,\n",
    "        \"batchnorm\": use_batchnorm,\n",
    "        \"early_stopping\": use_early_stopping,\n",
    "        \"epochs\": max_epochs,\n",
    "        \"lr\": lr\n",
    "    }, indent=2))\n",
    "\n",
    "    model = build_mlp(\n",
    "        input_dim=input_dim,\n",
    "        hidden_units=hidden_units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        l2_lambda=l2_lambda,\n",
    "        use_batchnorm=use_batchnorm,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    compile_model(model, lr)\n",
    "\n",
    "    callbacks = []\n",
    "    if use_early_stopping:\n",
    "        es = keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_accuracy\",\n",
    "            patience=patience,\n",
    "            mode=\"max\",\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "        callbacks.append(es)\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_split=VAL_SPLIT,\n",
    "        epochs=max_epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Evaluate on held-out test set\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "    # Find best val accuracy and epoch\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    best_epoch = int(np.argmax(val_acc)) + 1  # 1-based\n",
    "    best_val_acc = float(np.max(val_acc))\n",
    "\n",
    "    print(f\"[{run_name}] Best val_acc={best_val_acc:.4f} at epoch {best_epoch}, Test acc={test_acc:.4f}\")\n",
    "\n",
    "    # Save plots\n",
    "    fig1 = plt.figure()\n",
    "    plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.legend(); plt.title(run_name + \" - Accuracy\")\n",
    "    acc_path = os.path.join(OUTDIR, f\"{run_name}_accuracy.png\")\n",
    "    fig1.savefig(acc_path, dpi=160, bbox_inches=\"tight\")\n",
    "    plt.close(fig1)\n",
    "\n",
    "    fig2 = plt.figure()\n",
    "    plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.title(run_name + \" - Loss\")\n",
    "    loss_path = os.path.join(OUTDIR, f\"{run_name}_loss.png\")\n",
    "    fig2.savefig(loss_path, dpi=160, bbox_inches=\"tight\")\n",
    "    plt.close(fig2)\n",
    "\n",
    "    # Return summary row and history dict\n",
    "    row = {\n",
    "        \"run\": run_name,\n",
    "        \"hidden_units\": str(hidden_units),\n",
    "        \"dropout_rate\": dropout_rate,\n",
    "        \"l2_lambda\": l2_lambda,\n",
    "        \"batchnorm\": use_batchnorm,\n",
    "        \"early_stopping\": use_early_stopping,\n",
    "        \"epochs_run\": len(history.history[\"loss\"]),\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"best_val_acc\": best_val_acc,\n",
    "        \"test_acc\": float(test_acc),\n",
    "        \"acc_plot\": acc_path,\n",
    "        \"loss_plot\": loss_path\n",
    "    }\n",
    "    return row, history.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57108bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUN: baseline_mlp ===\n",
      "{\n",
      "  \"hidden_units\": [\n",
      "    512,\n",
      "    256\n",
      "  ],\n",
      "  \"dropout_rate\": 0.0,\n",
      "  \"l2_lambda\": 0.0,\n",
      "  \"batchnorm\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"epochs\": 60,\n",
      "  \"lr\": 0.001\n",
      "}\n",
      "Epoch 1/60\n",
      "157/157 - 4s - 22ms/step - accuracy: 0.2976 - loss: 1.9885 - val_accuracy: 0.3107 - val_loss: 1.9062\n",
      "Epoch 2/60\n",
      "157/157 - 3s - 16ms/step - accuracy: 0.3841 - loss: 1.7410 - val_accuracy: 0.3542 - val_loss: 1.8183\n",
      "Epoch 3/60\n",
      "157/157 - 3s - 16ms/step - accuracy: 0.4093 - loss: 1.6615 - val_accuracy: 0.3828 - val_loss: 1.7242\n",
      "Epoch 4/60\n",
      "157/157 - 3s - 18ms/step - accuracy: 0.4332 - loss: 1.5991 - val_accuracy: 0.4095 - val_loss: 1.6684\n",
      "Epoch 5/60\n",
      "157/157 - 3s - 19ms/step - accuracy: 0.4531 - loss: 1.5475 - val_accuracy: 0.4197 - val_loss: 1.6402\n",
      "Epoch 6/60\n",
      "157/157 - 3s - 16ms/step - accuracy: 0.4657 - loss: 1.5082 - val_accuracy: 0.4281 - val_loss: 1.6154\n",
      "Epoch 7/60\n",
      "157/157 - 4s - 23ms/step - accuracy: 0.4756 - loss: 1.4749 - val_accuracy: 0.4383 - val_loss: 1.5808\n",
      "Epoch 8/60\n",
      "157/157 - 3s - 17ms/step - accuracy: 0.4864 - loss: 1.4465 - val_accuracy: 0.4440 - val_loss: 1.5698\n",
      "Epoch 9/60\n",
      "157/157 - 3s - 20ms/step - accuracy: 0.4954 - loss: 1.4188 - val_accuracy: 0.4583 - val_loss: 1.5285\n",
      "Epoch 10/60\n",
      "157/157 - 3s - 20ms/step - accuracy: 0.5054 - loss: 1.3910 - val_accuracy: 0.4624 - val_loss: 1.5363\n",
      "Epoch 11/60\n",
      "157/157 - 3s - 16ms/step - accuracy: 0.5166 - loss: 1.3686 - val_accuracy: 0.4690 - val_loss: 1.5192\n",
      "Epoch 12/60\n",
      "157/157 - 3s - 21ms/step - accuracy: 0.5239 - loss: 1.3449 - val_accuracy: 0.4706 - val_loss: 1.5198\n",
      "Epoch 13/60\n",
      "157/157 - 3s - 19ms/step - accuracy: 0.5319 - loss: 1.3272 - val_accuracy: 0.4746 - val_loss: 1.4936\n",
      "Epoch 14/60\n",
      "157/157 - 4s - 23ms/step - accuracy: 0.5390 - loss: 1.3035 - val_accuracy: 0.4817 - val_loss: 1.4798\n",
      "Epoch 15/60\n",
      "157/157 - 3s - 16ms/step - accuracy: 0.5481 - loss: 1.2839 - val_accuracy: 0.4872 - val_loss: 1.4743\n",
      "Epoch 16/60\n",
      "157/157 - 2s - 16ms/step - accuracy: 0.5529 - loss: 1.2653 - val_accuracy: 0.4931 - val_loss: 1.4683\n",
      "Epoch 17/60\n",
      "157/157 - 3s - 20ms/step - accuracy: 0.5590 - loss: 1.2466 - val_accuracy: 0.4889 - val_loss: 1.4812\n",
      "Epoch 18/60\n",
      "157/157 - 3s - 16ms/step - accuracy: 0.5616 - loss: 1.2370 - val_accuracy: 0.4944 - val_loss: 1.4559\n",
      "Epoch 19/60\n",
      "157/157 - 3s - 17ms/step - accuracy: 0.5685 - loss: 1.2192 - val_accuracy: 0.4968 - val_loss: 1.4637\n",
      "Epoch 20/60\n",
      "157/157 - 3s - 20ms/step - accuracy: 0.5702 - loss: 1.2077 - val_accuracy: 0.4938 - val_loss: 1.4613\n",
      "Epoch 21/60\n",
      "157/157 - 3s - 17ms/step - accuracy: 0.5748 - loss: 1.1980 - val_accuracy: 0.4914 - val_loss: 1.4754\n",
      "Epoch 22/60\n",
      "157/157 - 3s - 21ms/step - accuracy: 0.5788 - loss: 1.1894 - val_accuracy: 0.4909 - val_loss: 1.4849\n",
      "Epoch 23/60\n",
      "157/157 - 4s - 22ms/step - accuracy: 0.5813 - loss: 1.1782 - val_accuracy: 0.4971 - val_loss: 1.4806\n",
      "Epoch 24/60\n",
      "157/157 - 3s - 17ms/step - accuracy: 0.5873 - loss: 1.1584 - val_accuracy: 0.5012 - val_loss: 1.4779\n",
      "Epoch 25/60\n",
      "157/157 - 3s - 18ms/step - accuracy: 0.5939 - loss: 1.1425 - val_accuracy: 0.4982 - val_loss: 1.4702\n",
      "Epoch 26/60\n",
      "157/157 - 3s - 19ms/step - accuracy: 0.6000 - loss: 1.1253 - val_accuracy: 0.4991 - val_loss: 1.4875\n",
      "Epoch 27/60\n",
      "157/157 - 3s - 21ms/step - accuracy: 0.6064 - loss: 1.1110 - val_accuracy: 0.5045 - val_loss: 1.4808\n",
      "Epoch 28/60\n",
      "157/157 - 3s - 21ms/step - accuracy: 0.6132 - loss: 1.0875 - val_accuracy: 0.4982 - val_loss: 1.4930\n",
      "Epoch 29/60\n",
      "157/157 - 3s - 22ms/step - accuracy: 0.6185 - loss: 1.0737 - val_accuracy: 0.4956 - val_loss: 1.5022\n",
      "Epoch 30/60\n",
      "157/157 - 4s - 28ms/step - accuracy: 0.6240 - loss: 1.0607 - val_accuracy: 0.4816 - val_loss: 1.5517\n",
      "Epoch 31/60\n",
      "157/157 - 4s - 28ms/step - accuracy: 0.6273 - loss: 1.0516 - val_accuracy: 0.4830 - val_loss: 1.5559\n",
      "Epoch 32/60\n",
      "157/157 - 4s - 23ms/step - accuracy: 0.6345 - loss: 1.0336 - val_accuracy: 0.4886 - val_loss: 1.5564\n",
      "Epoch 33/60\n",
      "157/157 - 4s - 23ms/step - accuracy: 0.6367 - loss: 1.0258 - val_accuracy: 0.4870 - val_loss: 1.5771\n",
      "Epoch 34/60\n",
      "157/157 - 4s - 25ms/step - accuracy: 0.6346 - loss: 1.0266 - val_accuracy: 0.4856 - val_loss: 1.5897\n",
      "Epoch 35/60\n",
      "157/157 - 4s - 25ms/step - accuracy: 0.6347 - loss: 1.0229 - val_accuracy: 0.4811 - val_loss: 1.6295\n",
      "Epoch 36/60\n",
      "157/157 - 4s - 23ms/step - accuracy: 0.6363 - loss: 1.0187 - val_accuracy: 0.4906 - val_loss: 1.5947\n",
      "Epoch 37/60\n",
      "157/157 - 4s - 23ms/step - accuracy: 0.6362 - loss: 1.0172 - val_accuracy: 0.4964 - val_loss: 1.5696\n",
      "Epoch 38/60\n",
      "157/157 - 4s - 23ms/step - accuracy: 0.6424 - loss: 1.0027 - val_accuracy: 0.4767 - val_loss: 1.6479\n",
      "Epoch 39/60\n",
      "157/157 - 3s - 22ms/step - accuracy: 0.6477 - loss: 0.9948 - val_accuracy: 0.4880 - val_loss: 1.6383\n",
      "Epoch 40/60\n",
      "157/157 - 4s - 22ms/step - accuracy: 0.6513 - loss: 0.9819 - val_accuracy: 0.4846 - val_loss: 1.6499\n",
      "Epoch 41/60\n",
      "157/157 - 3s - 22ms/step - accuracy: 0.6538 - loss: 0.9691 - val_accuracy: 0.4927 - val_loss: 1.6303\n",
      "Epoch 42/60\n",
      "157/157 - 4s - 24ms/step - accuracy: 0.6641 - loss: 0.9467 - val_accuracy: 0.4933 - val_loss: 1.6358\n",
      "Epoch 43/60\n",
      "157/157 - 4s - 23ms/step - accuracy: 0.6653 - loss: 0.9405 - val_accuracy: 0.4922 - val_loss: 1.6481\n",
      "Epoch 44/60\n",
      "157/157 - 4s - 23ms/step - accuracy: 0.6645 - loss: 0.9366 - val_accuracy: 0.4878 - val_loss: 1.6661\n",
      "Epoch 45/60\n",
      "157/157 - 4s - 26ms/step - accuracy: 0.6715 - loss: 0.9241 - val_accuracy: 0.4962 - val_loss: 1.6436\n",
      "Epoch 46/60\n",
      "157/157 - 4s - 25ms/step - accuracy: 0.6734 - loss: 0.9153 - val_accuracy: 0.4945 - val_loss: 1.6722\n",
      "Epoch 47/60\n",
      "157/157 - 4s - 24ms/step - accuracy: 0.6729 - loss: 0.9148 - val_accuracy: 0.4941 - val_loss: 1.6851\n",
      "Epoch 48/60\n",
      "157/157 - 4s - 25ms/step - accuracy: 0.6782 - loss: 0.9057 - val_accuracy: 0.4989 - val_loss: 1.6848\n",
      "Epoch 49/60\n",
      "157/157 - 4s - 24ms/step - accuracy: 0.6786 - loss: 0.9004 - val_accuracy: 0.4940 - val_loss: 1.7039\n",
      "Epoch 50/60\n",
      "157/157 - 4s - 26ms/step - accuracy: 0.6796 - loss: 0.8994 - val_accuracy: 0.4954 - val_loss: 1.6816\n",
      "Epoch 51/60\n",
      "157/157 - 6s - 35ms/step - accuracy: 0.6798 - loss: 0.8936 - val_accuracy: 0.4919 - val_loss: 1.7348\n",
      "Epoch 52/60\n",
      "157/157 - 4s - 26ms/step - accuracy: 0.6779 - loss: 0.9002 - val_accuracy: 0.4902 - val_loss: 1.7320\n",
      "Epoch 53/60\n",
      "157/157 - 4s - 24ms/step - accuracy: 0.6842 - loss: 0.8845 - val_accuracy: 0.4952 - val_loss: 1.7537\n",
      "Epoch 54/60\n",
      "157/157 - 4s - 25ms/step - accuracy: 0.6865 - loss: 0.8764 - val_accuracy: 0.4936 - val_loss: 1.7596\n",
      "Epoch 55/60\n",
      "157/157 - 4s - 25ms/step - accuracy: 0.6946 - loss: 0.8555 - val_accuracy: 0.4966 - val_loss: 1.7574\n",
      "Epoch 56/60\n",
      "157/157 - 4s - 24ms/step - accuracy: 0.6998 - loss: 0.8446 - val_accuracy: 0.4957 - val_loss: 1.7712\n",
      "Epoch 57/60\n",
      "157/157 - 4s - 23ms/step - accuracy: 0.7010 - loss: 0.8374 - val_accuracy: 0.4985 - val_loss: 1.7715\n",
      "Epoch 58/60\n",
      "157/157 - 4s - 25ms/step - accuracy: 0.7031 - loss: 0.8328 - val_accuracy: 0.4986 - val_loss: 1.7848\n",
      "Epoch 59/60\n",
      "157/157 - 4s - 23ms/step - accuracy: 0.7056 - loss: 0.8226 - val_accuracy: 0.4924 - val_loss: 1.7807\n",
      "Epoch 60/60\n",
      "157/157 - 4s - 23ms/step - accuracy: 0.7048 - loss: 0.8294 - val_accuracy: 0.4882 - val_loss: 1.8246\n",
      "[baseline_mlp] Best val_acc=0.5045 at epoch 27, Test acc=0.4868\n",
      "\n",
      "=== RUN: mlp_dropout ===\n",
      "{\n",
      "  \"hidden_units\": [\n",
      "    512,\n",
      "    256\n",
      "  ],\n",
      "  \"dropout_rate\": 0.5,\n",
      "  \"l2_lambda\": 0.0,\n",
      "  \"batchnorm\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"epochs\": 60,\n",
      "  \"lr\": 0.001\n",
      "}\n",
      "Epoch 1/60\n",
      "157/157 - 5s - 32ms/step - accuracy: 0.1951 - loss: 2.1596 - val_accuracy: 0.3024 - val_loss: 1.9544\n",
      "Epoch 2/60\n",
      "157/157 - 4s - 26ms/step - accuracy: 0.2406 - loss: 2.0236 - val_accuracy: 0.3188 - val_loss: 1.8919\n",
      "Epoch 3/60\n",
      "157/157 - 4s - 26ms/step - accuracy: 0.2577 - loss: 1.9881 - val_accuracy: 0.3204 - val_loss: 1.9044\n",
      "Epoch 4/60\n",
      "157/157 - 4s - 26ms/step - accuracy: 0.2684 - loss: 1.9543 - val_accuracy: 0.3310 - val_loss: 1.8963\n",
      "Epoch 5/60\n",
      "157/157 - 4s - 25ms/step - accuracy: 0.2788 - loss: 1.9426 - val_accuracy: 0.3418 - val_loss: 1.8791\n",
      "Epoch 6/60\n",
      "157/157 - 4s - 25ms/step - accuracy: 0.2859 - loss: 1.9298 - val_accuracy: 0.3466 - val_loss: 1.8830\n",
      "Epoch 7/60\n",
      "157/157 - 4s - 25ms/step - accuracy: 0.2935 - loss: 1.9123 - val_accuracy: 0.3321 - val_loss: 1.8983\n",
      "Epoch 8/60\n",
      "157/157 - 4s - 27ms/step - accuracy: 0.2875 - loss: 1.9124 - val_accuracy: 0.3591 - val_loss: 1.8928\n",
      "Epoch 9/60\n",
      "157/157 - 4s - 27ms/step - accuracy: 0.2900 - loss: 1.9089 - val_accuracy: 0.3575 - val_loss: 1.8739\n",
      "Epoch 10/60\n",
      "157/157 - 4s - 25ms/step - accuracy: 0.2950 - loss: 1.8910 - val_accuracy: 0.3418 - val_loss: 1.8788\n",
      "Epoch 11/60\n",
      "157/157 - 4s - 28ms/step - accuracy: 0.2963 - loss: 1.8967 - val_accuracy: 0.3543 - val_loss: 1.8973\n",
      "Epoch 12/60\n",
      "157/157 - 5s - 34ms/step - accuracy: 0.3038 - loss: 1.8804 - val_accuracy: 0.3458 - val_loss: 1.8653\n",
      "Epoch 13/60\n",
      "157/157 - 10s - 63ms/step - accuracy: 0.3093 - loss: 1.8666 - val_accuracy: 0.3591 - val_loss: 1.8591\n",
      "Epoch 14/60\n",
      "157/157 - 5s - 34ms/step - accuracy: 0.3121 - loss: 1.8645 - val_accuracy: 0.3460 - val_loss: 1.8681\n",
      "Epoch 15/60\n",
      "157/157 - 7s - 47ms/step - accuracy: 0.3147 - loss: 1.8577 - val_accuracy: 0.3711 - val_loss: 1.8451\n",
      "Epoch 16/60\n",
      "157/157 - 7s - 47ms/step - accuracy: 0.3117 - loss: 1.8575 - val_accuracy: 0.3523 - val_loss: 1.8708\n",
      "Epoch 17/60\n",
      "157/157 - 7s - 45ms/step - accuracy: 0.3211 - loss: 1.8548 - val_accuracy: 0.3676 - val_loss: 1.8479\n",
      "Epoch 18/60\n",
      "157/157 - 8s - 48ms/step - accuracy: 0.3176 - loss: 1.8459 - val_accuracy: 0.3583 - val_loss: 1.8648\n",
      "Epoch 19/60\n",
      "157/157 - 7s - 46ms/step - accuracy: 0.3188 - loss: 1.8448 - val_accuracy: 0.3791 - val_loss: 1.8397\n",
      "Epoch 20/60\n",
      "157/157 - 10s - 64ms/step - accuracy: 0.3229 - loss: 1.8368 - val_accuracy: 0.3707 - val_loss: 1.8411\n",
      "Epoch 21/60\n",
      "157/157 - 7s - 44ms/step - accuracy: 0.3227 - loss: 1.8343 - val_accuracy: 0.3805 - val_loss: 1.8181\n",
      "Epoch 22/60\n",
      "157/157 - 7s - 44ms/step - accuracy: 0.3233 - loss: 1.8361 - val_accuracy: 0.3829 - val_loss: 1.8271\n",
      "Epoch 23/60\n",
      "157/157 - 7s - 44ms/step - accuracy: 0.3259 - loss: 1.8323 - val_accuracy: 0.3837 - val_loss: 1.8268\n",
      "Epoch 24/60\n",
      "157/157 - 7s - 47ms/step - accuracy: 0.3279 - loss: 1.8274 - val_accuracy: 0.3814 - val_loss: 1.8158\n",
      "Epoch 25/60\n",
      "157/157 - 10s - 61ms/step - accuracy: 0.3280 - loss: 1.8256 - val_accuracy: 0.3738 - val_loss: 1.8289\n",
      "Epoch 26/60\n",
      "157/157 - 7s - 48ms/step - accuracy: 0.3305 - loss: 1.8145 - val_accuracy: 0.3838 - val_loss: 1.8136\n",
      "Epoch 27/60\n",
      "157/157 - 8s - 49ms/step - accuracy: 0.3362 - loss: 1.8140 - val_accuracy: 0.3814 - val_loss: 1.8331\n",
      "Epoch 28/60\n",
      "157/157 - 8s - 49ms/step - accuracy: 0.3317 - loss: 1.8173 - val_accuracy: 0.3840 - val_loss: 1.8136\n",
      "Epoch 29/60\n",
      "157/157 - 8s - 53ms/step - accuracy: 0.3349 - loss: 1.8069 - val_accuracy: 0.3845 - val_loss: 1.8196\n",
      "Epoch 30/60\n",
      "157/157 - 9s - 60ms/step - accuracy: 0.3340 - loss: 1.8094 - val_accuracy: 0.3884 - val_loss: 1.8126\n",
      "Epoch 31/60\n",
      "157/157 - 9s - 57ms/step - accuracy: 0.3381 - loss: 1.8030 - val_accuracy: 0.3826 - val_loss: 1.8093\n",
      "Epoch 32/60\n",
      "157/157 - 9s - 55ms/step - accuracy: 0.3399 - loss: 1.8027 - val_accuracy: 0.3945 - val_loss: 1.8094\n",
      "Epoch 33/60\n",
      "157/157 - 9s - 59ms/step - accuracy: 0.3355 - loss: 1.8091 - val_accuracy: 0.3784 - val_loss: 1.8228\n",
      "Epoch 34/60\n",
      "157/157 - 9s - 59ms/step - accuracy: 0.3409 - loss: 1.8013 - val_accuracy: 0.3902 - val_loss: 1.8077\n",
      "Epoch 35/60\n",
      "157/157 - 10s - 61ms/step - accuracy: 0.3384 - loss: 1.7997 - val_accuracy: 0.3823 - val_loss: 1.7946\n",
      "Epoch 36/60\n",
      "157/157 - 9s - 54ms/step - accuracy: 0.3403 - loss: 1.7961 - val_accuracy: 0.3850 - val_loss: 1.7868\n",
      "Epoch 37/60\n",
      "157/157 - 8s - 51ms/step - accuracy: 0.3386 - loss: 1.7975 - val_accuracy: 0.3723 - val_loss: 1.8195\n",
      "Epoch 38/60\n",
      "157/157 - 4s - 27ms/step - accuracy: 0.3440 - loss: 1.7887 - val_accuracy: 0.3901 - val_loss: 1.7861\n",
      "Epoch 39/60\n",
      "157/157 - 4s - 26ms/step - accuracy: 0.3399 - loss: 1.7993 - val_accuracy: 0.3762 - val_loss: 1.8231\n",
      "Epoch 40/60\n",
      "157/157 - 4s - 27ms/step - accuracy: 0.3415 - loss: 1.7931 - val_accuracy: 0.3904 - val_loss: 1.7959\n",
      "Epoch 41/60\n",
      "157/157 - 4s - 27ms/step - accuracy: 0.3485 - loss: 1.7798 - val_accuracy: 0.4008 - val_loss: 1.7817\n",
      "Epoch 42/60\n",
      "157/157 - 4s - 27ms/step - accuracy: 0.3446 - loss: 1.7881 - val_accuracy: 0.3801 - val_loss: 1.8109\n",
      "Epoch 43/60\n",
      "157/157 - 4s - 26ms/step - accuracy: 0.3466 - loss: 1.7881 - val_accuracy: 0.3891 - val_loss: 1.8082\n",
      "Epoch 44/60\n",
      "157/157 - 4s - 25ms/step - accuracy: 0.3458 - loss: 1.7773 - val_accuracy: 0.3937 - val_loss: 1.7965\n",
      "Epoch 45/60\n",
      "157/157 - 5s - 33ms/step - accuracy: 0.3452 - loss: 1.7788 - val_accuracy: 0.3924 - val_loss: 1.8039\n",
      "Epoch 46/60\n",
      "157/157 - 4s - 29ms/step - accuracy: 0.3502 - loss: 1.7712 - val_accuracy: 0.3858 - val_loss: 1.7929\n",
      "Epoch 47/60\n",
      "157/157 - 4s - 28ms/step - accuracy: 0.3494 - loss: 1.7781 - val_accuracy: 0.3909 - val_loss: 1.7916\n",
      "Epoch 48/60\n",
      "157/157 - 5s - 33ms/step - accuracy: 0.3519 - loss: 1.7728 - val_accuracy: 0.3921 - val_loss: 1.7999\n",
      "Epoch 49/60\n",
      "157/157 - 5s - 30ms/step - accuracy: 0.3512 - loss: 1.7747 - val_accuracy: 0.3928 - val_loss: 1.7903\n",
      "Epoch 50/60\n",
      "157/157 - 5s - 31ms/step - accuracy: 0.3473 - loss: 1.7770 - val_accuracy: 0.3831 - val_loss: 1.7893\n",
      "Epoch 51/60\n",
      "157/157 - 5s - 29ms/step - accuracy: 0.3501 - loss: 1.7764 - val_accuracy: 0.3788 - val_loss: 1.8105\n",
      "Epoch 52/60\n",
      "157/157 - 4s - 26ms/step - accuracy: 0.3479 - loss: 1.7788 - val_accuracy: 0.3910 - val_loss: 1.7995\n",
      "Epoch 53/60\n",
      "157/157 - 4s - 27ms/step - accuracy: 0.3532 - loss: 1.7668 - val_accuracy: 0.3904 - val_loss: 1.7970\n",
      "Epoch 54/60\n",
      "157/157 - 4s - 28ms/step - accuracy: 0.3489 - loss: 1.7712 - val_accuracy: 0.3810 - val_loss: 1.8108\n",
      "Epoch 55/60\n",
      "157/157 - 4s - 27ms/step - accuracy: 0.3542 - loss: 1.7648 - val_accuracy: 0.3835 - val_loss: 1.8053\n",
      "Epoch 56/60\n",
      "157/157 - 4s - 27ms/step - accuracy: 0.3505 - loss: 1.7707 - val_accuracy: 0.3855 - val_loss: 1.8013\n",
      "Epoch 57/60\n",
      "157/157 - 4s - 28ms/step - accuracy: 0.3536 - loss: 1.7686 - val_accuracy: 0.3941 - val_loss: 1.7998\n",
      "Epoch 58/60\n",
      "157/157 - 4s - 27ms/step - accuracy: 0.3525 - loss: 1.7708 - val_accuracy: 0.3659 - val_loss: 1.8217\n",
      "Epoch 59/60\n",
      "157/157 - 4s - 27ms/step - accuracy: 0.3558 - loss: 1.7573 - val_accuracy: 0.3902 - val_loss: 1.7907\n",
      "Epoch 60/60\n",
      "157/157 - 4s - 27ms/step - accuracy: 0.3499 - loss: 1.7702 - val_accuracy: 0.3811 - val_loss: 1.7958\n",
      "[mlp_dropout] Best val_acc=0.4008 at epoch 41, Test acc=0.3816\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Experiments\n",
    "# ---------------------------\n",
    "results = []\n",
    "histories = {}\n",
    "\n",
    "# 1) Baseline (no regularization)\n",
    "row, hist = train_experiment(\n",
    "    run_name=\"baseline_mlp\",\n",
    "    hidden_units=(512, 256),\n",
    "    dropout_rate=0.0,\n",
    "    l2_lambda=0.0,\n",
    "    use_batchnorm=False,\n",
    "    use_early_stopping=False,\n",
    "    max_epochs=EPOCHS\n",
    ")\n",
    "results.append(row); histories[row[\"run\"]] = hist\n",
    "\n",
    "# 2) + Dropout\n",
    "row, hist = train_experiment(\n",
    "    run_name=\"mlp_dropout\",\n",
    "    hidden_units=(512, 256),\n",
    "    dropout_rate=0.5,    # strong regularization for MLP on images\n",
    "    l2_lambda=0.0,\n",
    "    use_batchnorm=False,\n",
    "    use_early_stopping=False,\n",
    "    max_epochs=EPOCHS\n",
    ")\n",
    "results.append(row); histories[row[\"run\"]] = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34fd2ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUN: mlp_dropout_earlystop ===\n",
      "{\n",
      "  \"hidden_units\": [\n",
      "    512,\n",
      "    256\n",
      "  ],\n",
      "  \"dropout_rate\": 0.5,\n",
      "  \"l2_lambda\": 0.0,\n",
      "  \"batchnorm\": false,\n",
      "  \"early_stopping\": true,\n",
      "  \"epochs\": 20,\n",
      "  \"lr\": 0.001\n",
      "}\n",
      "Epoch 1/20\n",
      "157/157 - 6s - 35ms/step - accuracy: 0.1995 - loss: 2.1528 - val_accuracy: 0.3011 - val_loss: 1.9429\n",
      "Epoch 2/20\n",
      "157/157 - 5s - 34ms/step - accuracy: 0.2454 - loss: 2.0188 - val_accuracy: 0.3142 - val_loss: 1.9302\n",
      "Epoch 3/20\n",
      "157/157 - 5s - 31ms/step - accuracy: 0.2612 - loss: 1.9821 - val_accuracy: 0.3333 - val_loss: 1.9076\n",
      "Epoch 4/20\n",
      "157/157 - 5s - 29ms/step - accuracy: 0.2723 - loss: 1.9528 - val_accuracy: 0.3446 - val_loss: 1.8874\n",
      "Epoch 5/20\n",
      "157/157 - 5s - 34ms/step - accuracy: 0.2784 - loss: 1.9367 - val_accuracy: 0.3401 - val_loss: 1.8972\n",
      "Epoch 6/20\n",
      "157/157 - 5s - 33ms/step - accuracy: 0.2835 - loss: 1.9328 - val_accuracy: 0.3397 - val_loss: 1.8945\n",
      "Epoch 7/20\n",
      "157/157 - 4s - 28ms/step - accuracy: 0.2938 - loss: 1.9087 - val_accuracy: 0.3379 - val_loss: 1.8768\n",
      "Epoch 8/20\n",
      "157/157 - 4s - 28ms/step - accuracy: 0.2899 - loss: 1.9157 - val_accuracy: 0.3428 - val_loss: 1.8810\n",
      "Epoch 9/20\n",
      "157/157 - 4s - 27ms/step - accuracy: 0.2960 - loss: 1.8981 - val_accuracy: 0.3545 - val_loss: 1.8616\n",
      "Epoch 10/20\n",
      "157/157 - 4s - 26ms/step - accuracy: 0.2991 - loss: 1.8881 - val_accuracy: 0.3541 - val_loss: 1.8723\n",
      "Epoch 11/20\n",
      "157/157 - 4s - 29ms/step - accuracy: 0.3077 - loss: 1.8732 - val_accuracy: 0.3488 - val_loss: 1.8726\n",
      "Epoch 12/20\n",
      "157/157 - 5s - 30ms/step - accuracy: 0.3067 - loss: 1.8751 - val_accuracy: 0.3564 - val_loss: 1.8609\n",
      "Epoch 13/20\n",
      "157/157 - 4s - 27ms/step - accuracy: 0.3108 - loss: 1.8645 - val_accuracy: 0.3527 - val_loss: 1.8768\n",
      "Epoch 14/20\n",
      "157/157 - 5s - 32ms/step - accuracy: 0.3106 - loss: 1.8611 - val_accuracy: 0.3599 - val_loss: 1.8530\n",
      "Epoch 15/20\n",
      "157/157 - 4s - 27ms/step - accuracy: 0.3168 - loss: 1.8559 - val_accuracy: 0.3645 - val_loss: 1.8400\n",
      "Epoch 16/20\n",
      "157/157 - 4s - 26ms/step - accuracy: 0.3187 - loss: 1.8486 - val_accuracy: 0.3638 - val_loss: 1.8608\n",
      "Epoch 17/20\n",
      "157/157 - 4s - 25ms/step - accuracy: 0.3203 - loss: 1.8508 - val_accuracy: 0.3722 - val_loss: 1.8433\n",
      "Epoch 18/20\n",
      "157/157 - 4s - 27ms/step - accuracy: 0.3194 - loss: 1.8475 - val_accuracy: 0.3665 - val_loss: 1.8505\n",
      "Epoch 19/20\n",
      "157/157 - 7s - 44ms/step - accuracy: 0.3210 - loss: 1.8474 - val_accuracy: 0.3568 - val_loss: 1.8329\n",
      "Epoch 20/20\n",
      "157/157 - 6s - 40ms/step - accuracy: 0.3227 - loss: 1.8388 - val_accuracy: 0.3822 - val_loss: 1.8365\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "[mlp_dropout_earlystop] Best val_acc=0.3822 at epoch 20, Test acc=0.3871\n"
     ]
    }
   ],
   "source": [
    "# 3) + Early Stopping (same as dropout config but with ES)\n",
    "row, hist = train_experiment(\n",
    "    run_name=\"mlp_dropout_earlystop\",\n",
    "    hidden_units=(512, 256),\n",
    "    dropout_rate=0.5,\n",
    "    l2_lambda=0.0,\n",
    "    use_batchnorm=False,\n",
    "    use_early_stopping=True,\n",
    "    patience=8,\n",
    "    max_epochs=20\n",
    ")\n",
    "results.append(row); histories[row[\"run\"]] = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a4b889d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUN: mlp_l2 ===\n",
      "{\n",
      "  \"hidden_units\": [\n",
      "    512,\n",
      "    256\n",
      "  ],\n",
      "  \"dropout_rate\": 0.0,\n",
      "  \"l2_lambda\": 0.0001,\n",
      "  \"batchnorm\": false,\n",
      "  \"early_stopping\": true,\n",
      "  \"epochs\": 20,\n",
      "  \"lr\": 0.001\n",
      "}\n",
      "Epoch 1/20\n",
      "157/157 - 10s - 62ms/step - accuracy: 0.2830 - loss: 2.1340 - val_accuracy: 0.3277 - val_loss: 1.9494\n",
      "Epoch 2/20\n",
      "157/157 - 6s - 35ms/step - accuracy: 0.3743 - loss: 1.8338 - val_accuracy: 0.3734 - val_loss: 1.8215\n",
      "Epoch 3/20\n",
      "157/157 - 7s - 44ms/step - accuracy: 0.4099 - loss: 1.7321 - val_accuracy: 0.3932 - val_loss: 1.7620\n",
      "Epoch 4/20\n",
      "157/157 - 6s - 36ms/step - accuracy: 0.4283 - loss: 1.6685 - val_accuracy: 0.4102 - val_loss: 1.7161\n",
      "Epoch 5/20\n",
      "157/157 - 7s - 43ms/step - accuracy: 0.4506 - loss: 1.6096 - val_accuracy: 0.4209 - val_loss: 1.6997\n",
      "Epoch 6/20\n",
      "157/157 - 7s - 46ms/step - accuracy: 0.4642 - loss: 1.5675 - val_accuracy: 0.4307 - val_loss: 1.6890\n",
      "Epoch 7/20\n",
      "157/157 - 6s - 38ms/step - accuracy: 0.4744 - loss: 1.5351 - val_accuracy: 0.4324 - val_loss: 1.6838\n",
      "Epoch 8/20\n",
      "157/157 - 6s - 41ms/step - accuracy: 0.4836 - loss: 1.5026 - val_accuracy: 0.4426 - val_loss: 1.6375\n",
      "Epoch 9/20\n",
      "157/157 - 6s - 41ms/step - accuracy: 0.4921 - loss: 1.4771 - val_accuracy: 0.4446 - val_loss: 1.6387\n",
      "Epoch 10/20\n",
      "157/157 - 6s - 40ms/step - accuracy: 0.4988 - loss: 1.4548 - val_accuracy: 0.4610 - val_loss: 1.5914\n",
      "Epoch 11/20\n",
      "157/157 - 5s - 31ms/step - accuracy: 0.5045 - loss: 1.4379 - val_accuracy: 0.4596 - val_loss: 1.5819\n",
      "Epoch 12/20\n",
      "157/157 - 7s - 43ms/step - accuracy: 0.5125 - loss: 1.4179 - val_accuracy: 0.4652 - val_loss: 1.5787\n",
      "Epoch 13/20\n",
      "157/157 - 7s - 45ms/step - accuracy: 0.5173 - loss: 1.3999 - val_accuracy: 0.4630 - val_loss: 1.5679\n",
      "Epoch 14/20\n",
      "157/157 - 7s - 47ms/step - accuracy: 0.5213 - loss: 1.3908 - val_accuracy: 0.4620 - val_loss: 1.5555\n",
      "Epoch 15/20\n",
      "157/157 - 5s - 35ms/step - accuracy: 0.5252 - loss: 1.3793 - val_accuracy: 0.4851 - val_loss: 1.5154\n",
      "Epoch 16/20\n",
      "157/157 - 5s - 34ms/step - accuracy: 0.5309 - loss: 1.3622 - val_accuracy: 0.4837 - val_loss: 1.5138\n",
      "Epoch 17/20\n",
      "157/157 - 7s - 44ms/step - accuracy: 0.5387 - loss: 1.3466 - val_accuracy: 0.4752 - val_loss: 1.5369\n",
      "Epoch 18/20\n",
      "157/157 - 7s - 43ms/step - accuracy: 0.5459 - loss: 1.3311 - val_accuracy: 0.4839 - val_loss: 1.5314\n",
      "Epoch 19/20\n",
      "157/157 - 7s - 46ms/step - accuracy: 0.5507 - loss: 1.3166 - val_accuracy: 0.4892 - val_loss: 1.5196\n",
      "Epoch 20/20\n",
      "157/157 - 7s - 45ms/step - accuracy: 0.5576 - loss: 1.2996 - val_accuracy: 0.4911 - val_loss: 1.5255\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "[mlp_l2] Best val_acc=0.4911 at epoch 20, Test acc=0.4934\n"
     ]
    }
   ],
   "source": [
    "# 4) + L2 (weight decay) — compare to dropout\n",
    "row, hist = train_experiment(\n",
    "    run_name=\"mlp_l2\",\n",
    "    hidden_units=(512, 256),\n",
    "    dropout_rate=0.0,\n",
    "    l2_lambda=1e-4,   # typical small L2\n",
    "    use_batchnorm=False,\n",
    "    use_early_stopping=True,  # ES works well with L2 too\n",
    "    patience=8,\n",
    "    max_epochs=20\n",
    ")\n",
    "results.append(row); histories[row[\"run\"]] = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f36ea550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUN: mlp_deeper ===\n",
      "{\n",
      "  \"hidden_units\": [\n",
      "    1024,\n",
      "    512,\n",
      "    256,\n",
      "    128\n",
      "  ],\n",
      "  \"dropout_rate\": 0.5,\n",
      "  \"l2_lambda\": 0.0001,\n",
      "  \"batchnorm\": false,\n",
      "  \"early_stopping\": true,\n",
      "  \"epochs\": 20,\n",
      "  \"lr\": 0.001\n",
      "}\n",
      "Epoch 1/20\n",
      "157/157 - 17s - 106ms/step - accuracy: 0.1287 - loss: 2.5435 - val_accuracy: 0.1795 - val_loss: 2.3233\n",
      "Epoch 2/20\n",
      "157/157 - 14s - 92ms/step - accuracy: 0.1769 - loss: 2.3130 - val_accuracy: 0.2356 - val_loss: 2.2226\n",
      "Epoch 3/20\n",
      "157/157 - 12s - 76ms/step - accuracy: 0.2012 - loss: 2.2225 - val_accuracy: 0.2515 - val_loss: 2.1473\n",
      "Epoch 4/20\n",
      "157/157 - 13s - 80ms/step - accuracy: 0.2151 - loss: 2.1678 - val_accuracy: 0.2485 - val_loss: 2.1066\n",
      "Epoch 5/20\n",
      "157/157 - 14s - 87ms/step - accuracy: 0.2271 - loss: 2.1295 - val_accuracy: 0.2565 - val_loss: 2.1022\n",
      "Epoch 6/20\n",
      "157/157 - 14s - 91ms/step - accuracy: 0.2309 - loss: 2.0983 - val_accuracy: 0.2422 - val_loss: 2.0891\n",
      "Epoch 7/20\n",
      "157/157 - 20s - 130ms/step - accuracy: 0.2373 - loss: 2.0660 - val_accuracy: 0.2580 - val_loss: 2.0409\n",
      "Epoch 8/20\n",
      "157/157 - 14s - 86ms/step - accuracy: 0.2432 - loss: 2.0445 - val_accuracy: 0.2693 - val_loss: 2.0523\n",
      "Epoch 9/20\n",
      "157/157 - 13s - 83ms/step - accuracy: 0.2421 - loss: 2.0379 - val_accuracy: 0.2710 - val_loss: 2.0272\n",
      "Epoch 10/20\n",
      "157/157 - 14s - 88ms/step - accuracy: 0.2483 - loss: 2.0197 - val_accuracy: 0.2478 - val_loss: 2.0271\n",
      "Epoch 11/20\n",
      "157/157 - 13s - 85ms/step - accuracy: 0.2512 - loss: 2.0149 - val_accuracy: 0.2491 - val_loss: 2.0284\n",
      "Epoch 12/20\n",
      "157/157 - 13s - 85ms/step - accuracy: 0.2519 - loss: 2.0057 - val_accuracy: 0.2507 - val_loss: 2.0382\n",
      "Epoch 13/20\n",
      "157/157 - 13s - 81ms/step - accuracy: 0.2457 - loss: 2.0022 - val_accuracy: 0.2574 - val_loss: 2.0085\n",
      "Epoch 14/20\n",
      "157/157 - 13s - 85ms/step - accuracy: 0.2498 - loss: 1.9988 - val_accuracy: 0.2599 - val_loss: 2.0126\n",
      "Epoch 15/20\n",
      "157/157 - 13s - 84ms/step - accuracy: 0.2536 - loss: 1.9938 - val_accuracy: 0.2683 - val_loss: 1.9875\n",
      "Epoch 16/20\n",
      "157/157 - 14s - 88ms/step - accuracy: 0.2565 - loss: 1.9894 - val_accuracy: 0.2557 - val_loss: 2.0041\n",
      "Epoch 17/20\n",
      "157/157 - 14s - 91ms/step - accuracy: 0.2580 - loss: 1.9836 - val_accuracy: 0.2630 - val_loss: 1.9909\n",
      "Epoch 18/20\n",
      "157/157 - 14s - 87ms/step - accuracy: 0.2624 - loss: 1.9812 - val_accuracy: 0.2487 - val_loss: 2.0154\n",
      "Epoch 19/20\n",
      "157/157 - 14s - 91ms/step - accuracy: 0.2585 - loss: 1.9765 - val_accuracy: 0.2515 - val_loss: 2.0336\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "[mlp_deeper] Best val_acc=0.2710 at epoch 9, Test acc=0.2708\n"
     ]
    }
   ],
   "source": [
    "# 5) Deeper model (more capacity  more overfitting risk)\n",
    "row, hist = train_experiment(\n",
    "    run_name=\"mlp_deeper\",\n",
    "    hidden_units=(1024, 512, 256, 128),\n",
    "    dropout_rate=0.5,     # keep some regularization so it trains\n",
    "    l2_lambda=1e-4,       # combine L2 to study effect on depth\n",
    "    use_batchnorm=False,\n",
    "    use_early_stopping=True,\n",
    "    patience=10,\n",
    "    max_epochs=20\n",
    ")\n",
    "results.append(row); histories[row[\"run\"]] = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32958dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY (Acceptance Criteria) ===\n",
      "Baseline best val_acc=0.5045 at epoch 27 (epochs run=60)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Save summary & histories\n",
    "# ---------------------------\n",
    "df = pd.DataFrame(results)\n",
    "csv_path = os.path.join(OUTDIR, \"results_summary.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "with open(os.path.join(OUTDIR, \"histories.json\"), \"w\") as f:\n",
    "    json.dump(histories, f)\n",
    "\n",
    "print(\"\\n=== SUMMARY (Acceptance Criteria) ===\")\n",
    "# 1) Baseline model without regularization\n",
    "base = df[df[\"run\"]==\"baseline_mlp\"].iloc[0]\n",
    "print(f\"Baseline best val_acc={base['best_val_acc']:.4f} at epoch {base['best_epoch']} (epochs run={base['epochs_run']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5caa4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout best val_acc=0.4008 at epoch 41\n"
     ]
    }
   ],
   "source": [
    "# 2) Add dropout and compare\n",
    "drop = df[df[\"run\"]==\"mlp_dropout\"].iloc[0]\n",
    "print(f\"Dropout best val_acc={drop['best_val_acc']:.4f} at epoch {drop['best_epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3b5879d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout+EarlyStopping best val_acc=0.3822 at epoch 20 (epochs run=20)\n",
      "L2 best val_acc=0.4911 at epoch 20\n",
      "Deeper model best val_acc=0.2710 at epoch 9 (epochs run=19)\n",
      "\n",
      "Saved:\n",
      "- Per-run accuracy/loss plots: mlp_cifar10_runs/*_accuracy.png, *_loss.png\n",
      "- CSV summary: mlp_cifar10_runs\\results_summary.csv\n",
      "- Full histories JSON: mlp_cifar10_runs\\histories.json\n"
     ]
    }
   ],
   "source": [
    "# 3) Early stopping best epoch recorded\n",
    "drop_es = df[df[\"run\"]==\"mlp_dropout_earlystop\"].iloc[0]\n",
    "print(f\"Dropout+EarlyStopping best val_acc={drop_es['best_val_acc']:.4f} at epoch {drop_es['best_epoch']} (epochs run={drop_es['epochs_run']})\")\n",
    "\n",
    "# 4) L2 weight regularization\n",
    "l2r = df[df[\"run\"]==\"mlp_l2\"].iloc[0]\n",
    "print(f\"L2 best val_acc={l2r['best_val_acc']:.4f} at epoch {l2r['best_epoch']}\")\n",
    "\n",
    "# 5) Depth effects (deeper model)\n",
    "deep = df[df[\"run\"]==\"mlp_deeper\"].iloc[0]\n",
    "print(f\"Deeper model best val_acc={deep['best_val_acc']:.4f} at epoch {deep['best_epoch']} (epochs run={deep['epochs_run']})\")\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(f\"- Per-run accuracy/loss plots: {OUTDIR}/*_accuracy.png, *_loss.png\")\n",
    "print(f\"- CSV summary: {csv_path}\")\n",
    "print(f\"- Full histories JSON: {os.path.join(OUTDIR, 'histories.json')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
