{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b6a51a1-78d4-4afa-902b-7c6ba6bd8c5b",
   "metadata": {},
   "source": [
    "# IMDb Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf9bd09-bef8-4d5f-825d-519d16bd496c",
   "metadata": {},
   "source": [
    "### ðŸ“¦ 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51bfd4f6-d2d5-45c1-bf8a-1e6afe000c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bbuser\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bbuser\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\bbuser\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f045e6-fea4-4c09-b5b9-50cb9931ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f0422-8c79-4f9c-b543-d6a1ed5afcb3",
   "metadata": {},
   "source": [
    "### ðŸ“ 2. Load Reviews from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec49557-d3cf-4253-960f-4e9f23d1e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def load_reviews_from_dir(directory, label):\n",
    "    files = glob.glob(directory + \"/*.txt\")\n",
    "    data = []\n",
    "    for f in files:\n",
    "        with open(f, encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "            data.append([text, label])\n",
    "    return pd.DataFrame(data, columns=['review', 'sentiment'])\n",
    "\n",
    "train_pos = \"aclImdb_v1/aclImdb/train/pos\"\n",
    "train_neg = \"aclImdb_v1/aclImdb/train/neg\"\n",
    "\n",
    "\n",
    "df_train = pd.concat([\n",
    "    load_reviews_from_dir(train_pos, 'positive'),\n",
    "    load_reviews_from_dir(train_neg, 'negative')\n",
    "], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a9c7e-0068-4265-8907-63d187ee56e5",
   "metadata": {},
   "source": [
    "> **Explanation:**\n",
    "This function reads all text files from a specified directory (positive or negative IMDB reviews), labels them accordingly, and returns a single DataFrame. Both positive and negative reviews are concatenated into one training DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df127a7-dfc5-45b2-9b41-076738939089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...  positive\n",
       "1  Homelessness (or Houselessness as George Carli...  positive\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...  positive\n",
       "3  This is easily the most underrated film inn th...  positive\n",
       "4  This is not the typical Mel Brooks film. It wa...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f761b507-9004-4d13-ae30-84989dd777bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6957c717-c0fd-4144-bb97-b6cb4a2a7795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=25000, step=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a52904-96f8-4fa8-9bb2-de4aa3784d4e",
   "metadata": {},
   "source": [
    "### ðŸ“Š 3. Sample a Subset of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b0699e-8355-4f31-8a62-783b933e64e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_train.sample(n=10000, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d02679-80be-4752-824c-e18fa4954bf0",
   "metadata": {},
   "source": [
    "> **Explanation:**\n",
    "To improve processing speed, a random sample of 10,000 reviews is taken from the training set using a fixed random seed for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f04f87-f565-49a3-8850-94d7db2a8abe",
   "metadata": {},
   "source": [
    "### ðŸ§¹ 4. Clean and Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e95db3b-a3c7-42da-b5a5-9df09802bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def clean_review(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "    # Remove URLs and emails\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "\n",
    "    # Remove punctuation, numbers, and non-letters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Remove stopwords & short tokens, lemmatize\n",
    "    cleaned_tokens = [\n",
    "        lemmatizer.lemmatize(word)\n",
    "        for word in tokens\n",
    "        if word not in stop_words and len(word) > 2\n",
    "    ]\n",
    "\n",
    "    # Join tokens back to string\n",
    "    return \" \".join(cleaned_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3e0776-1f19-4faa-92c4-9c2061f1658b",
   "metadata": {},
   "source": [
    "> **Explanation:**\n",
    "The `clean_review` function performs several preprocessing steps:\n",
    "> - Lowercasing\n",
    "> - Removing HTML, URLs, and emails\n",
    "> - Removing punctuation and digits\n",
    "> - Tokenization\n",
    "> - Stopword removal and lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849508a-1f9c-4c76-86b8-63ab51972004",
   "metadata": {},
   "source": [
    "### ðŸ§¼ 5. Apply Cleaning to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "005f76db-7445-4d34-828e-5423ac7c74e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['cleaned_review'] = df_sample['review'].apply(clean_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4a2303-b097-4e9a-9271-5a23cdb3dd67",
   "metadata": {},
   "source": [
    "> **Explanation:**\n",
    "The cleaning function is applied to every review in the sample dataset to create a new column, `cleaned_review`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b2609-85a6-4a92-9ce4-da71a0eff55d",
   "metadata": {},
   "source": [
    "### ðŸ‘€ 6. Preview Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87be50f9-46fd-4971-938f-82a02fef5197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In Panic In The Streets Richard Widmark plays ...</td>\n",
       "      <td>panic street richard widmark play navy doctor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you ask me the first one was really better ...</td>\n",
       "      <td>ask first one really better one look sarah rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am a big fan a Faerie Tale Theatre and I've ...</td>\n",
       "      <td>big fan faerie tale theatre ive seen one best ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I just finished reading a book about Dillinger...</td>\n",
       "      <td>finished reading book dillinger movie horribly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greg Davis and Bryan Daly take some crazed sta...</td>\n",
       "      <td>greg davis bryan daly take crazed statement te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  In Panic In The Streets Richard Widmark plays ...   \n",
       "1  If you ask me the first one was really better ...   \n",
       "2  I am a big fan a Faerie Tale Theatre and I've ...   \n",
       "3  I just finished reading a book about Dillinger...   \n",
       "4  Greg Davis and Bryan Daly take some crazed sta...   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  panic street richard widmark play navy doctor ...  \n",
       "1  ask first one really better one look sarah rea...  \n",
       "2  big fan faerie tale theatre ive seen one best ...  \n",
       "3  finished reading book dillinger movie horribly...  \n",
       "4  greg davis bryan daly take crazed statement te...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[['review', 'cleaned_review']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbeb8df-5874-4b67-bd22-8d81c1cc712d",
   "metadata": {},
   "source": [
    "### ðŸ’¾ 7. Save Cleaned Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48ef7442-6231-413d-88a8-0e27c1b92249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_csv(\"cleaned_imdb_sample.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
