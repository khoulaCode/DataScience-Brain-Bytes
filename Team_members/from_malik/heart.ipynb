{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6b5c69-c458-4b6e-8865-81bb358e53e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9709cda9-3609-423c-b669-4347f95ea67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1025, 14)\n",
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
      "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
      "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
      "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
      "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   2     3       0  \n",
      "1   0     3       0  \n",
      "2   0     3       0  \n",
      "3   1     3       0  \n",
      "4   3     2       0  \n"
     ]
    }
   ],
   "source": [
    "# --- Load Dataset ---\n",
    "data = pd.read_csv(\"heart.csv\")\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fde0c69-a71a-4227-a2cd-38d39e3e600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Separate features and target ---\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cf71932-4436-46dc-86f5-1fee7309de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical columns if any (optional but good practice)\n",
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc59d727-2b0f-445b-903a-6f3f2dcdc8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Split into training and testing sets ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4769339-6ca4-4ea9-8da2-c97e01139d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define a simple neural network model ---\n",
    "def build_model(input_dim):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(16, activation='relu', input_shape=(input_dim,)),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df0ec52-1c41-4e9e-946b-06bf936092d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper function to train and evaluate ---\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, desc):\n",
    "    model = build_model(X_train.shape[1])\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=16,\n",
    "                        validation_split=0.2, verbose=0)\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    print(f\"\\n--- {desc} ---\")\n",
    "    print(f\"Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f42e447b-1003-4dde-bf5e-9cf0ccf1f2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbuser\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step \n",
      "\n",
      "--- Raw (Unscaled) ---\n",
      "Accuracy: 0.771, Precision: 0.764, Recall: 0.786\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Raw Data ---\n",
    "hist_raw = train_and_evaluate(X_train, X_test, y_train, y_test, \"Raw (Unscaled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0b8cfd0-87cc-4937-98c2-c510c6fece37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbuser\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step \n",
      "\n",
      "--- MinMax Scaled ---\n",
      "Accuracy: 0.839, Precision: 0.812, Recall: 0.883\n"
     ]
    }
   ],
   "source": [
    "# --- 2. MinMax Scaled ---\n",
    "scaler_mm = MinMaxScaler()\n",
    "X_train_mm = scaler_mm.fit_transform(X_train)\n",
    "X_test_mm = scaler_mm.transform(X_test)\n",
    "hist_mm = train_and_evaluate(X_train_mm, X_test_mm, y_train, y_test, \"MinMax Scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75544eca-9648-4a61-a933-ec3213e27c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbuser\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000019949C31760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step \n",
      "\n",
      "--- Standard Scaled ---\n",
      "Accuracy: 0.873, Precision: 0.860, Recall: 0.893\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Standard Scaled ---\n",
    "scaler_std = StandardScaler()\n",
    "X_train_std = scaler_std.fit_transform(X_train)\n",
    "X_test_std = scaler_std.transform(X_test)\n",
    "hist_std = train_and_evaluate(X_train_std, X_test_std, y_train, y_test, \"Standard Scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d8d6b5-3107-471c-8fed-fd477a8e0300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
