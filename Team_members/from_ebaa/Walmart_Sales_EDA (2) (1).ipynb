{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6db1cb2b-9549-4935-88f0-01788a28d354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Shapes of DataFrames ===\n",
      "Train: (421570, 5)\n",
      "Features: (8190, 12)\n",
      "Stores: (45, 3)\n",
      "\n",
      "=== Train Data (first 5 rows) ===\n",
      "   Store  Dept       Date  Weekly_Sales  IsHoliday\n",
      "0      1     1 2010-02-05      24924.50      False\n",
      "1      1     1 2010-02-12      46039.49       True\n",
      "2      1     1 2010-02-19      41595.55      False\n",
      "3      1     1 2010-02-26      19403.54      False\n",
      "4      1     1 2010-03-05      21827.90      False\n",
      "\n",
      "=== Features Data (first 5 rows) ===\n",
      "   Store       Date  Temperature  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  \\\n",
      "0      1 2010-02-05        42.31       2.572        NaN        NaN        NaN   \n",
      "1      1 2010-02-12        38.51       2.548        NaN        NaN        NaN   \n",
      "2      1 2010-02-19        39.93       2.514        NaN        NaN        NaN   \n",
      "3      1 2010-02-26        46.63       2.561        NaN        NaN        NaN   \n",
      "4      1 2010-03-05        46.50       2.625        NaN        NaN        NaN   \n",
      "\n",
      "   MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  \n",
      "0        NaN        NaN  211.096358         8.106      False  \n",
      "1        NaN        NaN  211.242170         8.106       True  \n",
      "2        NaN        NaN  211.289143         8.106      False  \n",
      "3        NaN        NaN  211.319643         8.106      False  \n",
      "4        NaN        NaN  211.350143         8.106      False  \n",
      "\n",
      "=== Stores Data (first 5 rows) ===\n",
      "   Store Type    Size\n",
      "0      1    A  151315\n",
      "1      2    A  202307\n",
      "2      3    B   37392\n",
      "3      4    A  205863\n",
      "4      5    B   34875\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the folder path where the files are located\n",
    "folder_path = \"C:\\\\Users\\\\bbuser\\\\Downloads\\\\walmart-recruiting-store-sales-forecasting\\\\\"\n",
    "\n",
    "# Load the CSV files with 'Date' column parsed where needed\n",
    "train_df = pd.read_csv(folder_path + \"train.csv\", parse_dates=[\"Date\"])\n",
    "features_df = pd.read_csv(folder_path + \"features.csv\", parse_dates=[\"Date\"])\n",
    "stores_df = pd.read_csv(folder_path + \"stores.csv\")\n",
    "\n",
    "# Print the shapes of all DataFrames\n",
    "print(\"=== Shapes of DataFrames ===\")\n",
    "print(\"Train:\", train_df.shape)\n",
    "print(\"Features:\", features_df.shape)\n",
    "print(\"Stores:\", stores_df.shape)\n",
    "\n",
    "# Print first 5 rows of each DataFrame\n",
    "print(\"\\n=== Train Data (first 5 rows) ===\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\n=== Features Data (first 5 rows) ===\")\n",
    "print(features_df.head())\n",
    "\n",
    "print(\"\\n=== Stores Data (first 5 rows) ===\")\n",
    "print(stores_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd318058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "Train: (421570, 5)\n",
      "Features: (8190, 12)\n",
      "Stores: (45, 3)\n",
      "\n",
      "Train head:\n",
      "   Store  Dept       Date  Weekly_Sales  IsHoliday\n",
      "0      1     1 2010-02-05      24924.50      False\n",
      "1      1     1 2010-02-12      46039.49       True\n",
      "2      1     1 2010-02-19      41595.55      False\n",
      "3      1     1 2010-02-26      19403.54      False\n",
      "4      1     1 2010-03-05      21827.90      False\n"
     ]
    }
   ],
   "source": [
    "# Show shapes of the dataframes\n",
    "print(\"Shapes:\")\n",
    "print(\"Train:\", train_df.shape)\n",
    "print(\"Features:\", features_df.shape)\n",
    "print(\"Stores:\", stores_df.shape)\n",
    "\n",
    "# Display first few rows of the train DataFrame\n",
    "print(\"\\nTrain head:\")\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d32d865-4a12-4f23-b5dd-c49f9c78e810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape comparison:\n",
      "Original train: (421570, 5)\n",
      "Concatenated part1 + part2: (2000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Example: split train into two parts and concatenate back\n",
    "part1 = train_df.head(1000)\n",
    "part2 = train_df.tail(1000)\n",
    "concat = pd.concat([part1, part2])\n",
    "\n",
    "print(\"\\nShape comparison:\")\n",
    "print(\"Original train:\", train_df.shape)\n",
    "print(\"Concatenated part1 + part2:\", concat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be93e9-de56-4124-8250-c0fd34dcd1a9",
   "metadata": {},
   "source": [
    "# Explore the Datasets (Basic EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c5e915a-1f48-45e4-b605-e79cbbbf6f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (421570, 5)\n",
      "Features: (8190, 12)\n",
      "Stores: (45, 3)\n"
     ]
    }
   ],
   "source": [
    "# Check dataset shapes\n",
    "print(\"Train:\", train_df.shape)\n",
    "print(\"Features:\", features_df.shape)\n",
    "print(\"Stores:\", stores_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "643f6569-7056-4650-a10a-c6a0378fddf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in train:\n",
      "Store           0\n",
      "Dept            0\n",
      "Date            0\n",
      "Weekly_Sales    0\n",
      "IsHoliday       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "print(\"\\nMissing values in train:\")\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76667d9-010a-4beb-a600-7a171d656c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 421570 entries, 0 to 421569\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Store         421570 non-null  int64  \n",
      " 1   Dept          421570 non-null  int64  \n",
      " 2   Date          421570 non-null  object \n",
      " 3   Weekly_Sales  421570 non-null  float64\n",
      " 4   IsHoliday     421570 non-null  bool   \n",
      "dtypes: bool(1), float64(1), int64(2), object(1)\n",
      "memory usage: 13.3+ MB\n",
      "None\n",
      "               Store           Dept   Weekly_Sales\n",
      "count  421570.000000  421570.000000  421570.000000\n",
      "mean       22.200546      44.260317   15981.258123\n",
      "std        12.785297      30.492054   22711.183519\n",
      "min         1.000000       1.000000   -4988.940000\n",
      "25%        11.000000      18.000000    2079.650000\n",
      "50%        22.000000      37.000000    7612.030000\n",
      "75%        33.000000      74.000000   20205.852500\n",
      "max        45.000000      99.000000  693099.360000\n"
     ]
    }
   ],
   "source": [
    "# Check data types and summary\n",
    "print(train_df.info())\n",
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9f18c0-0408-4d69-a0d5-4a0dc8ce6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values\n",
    "print(train_df['Store'].value_counts().head())\n",
    "print(train_df['Dept'].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a38a879-9fe6-4df0-b206-ec3092f7592a",
   "metadata": {},
   "source": [
    "# 2. Aggregate Sales Using groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da62453f-a4f5-4905-92c1-13b46cbea405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store\n",
      "20    3.013978e+08\n",
      "4     2.995440e+08\n",
      "14    2.889999e+08\n",
      "13    2.865177e+08\n",
      "2     2.753824e+08\n",
      "Name: Weekly_Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Total sales by store\n",
    "\n",
    "sales_by_store = train_df.groupby('Store')['Weekly_Sales'].sum().sort_values(ascending=False)\n",
    "print(sales_by_store.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81883018-1759-4e76-a655-61d46e41ceee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dept\n",
      "92    4.839433e+08\n",
      "95    4.493202e+08\n",
      "38    3.931181e+08\n",
      "72    3.057252e+08\n",
      "90    2.910685e+08\n",
      "Name: Weekly_Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Total sales by department\n",
    "\n",
    "sales_by_dept = train_df.groupby('Dept')['Weekly_Sales'].sum().sort_values(ascending=False)\n",
    "print(sales_by_dept.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9df3b52-2118-47be-897d-69dfd47a8067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store\n",
      "1    21710.543621\n",
      "2    26898.070031\n",
      "3     6373.033983\n",
      "4    29161.210415\n",
      "5     5053.415813\n",
      "Name: Weekly_Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Average weekly sales by store\n",
    "\n",
    "avg_sales_store = train_df.groupby('Store')['Weekly_Sales'].mean()\n",
    "print(avg_sales_store.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9000b27-83ea-4c12-a7c3-20ef8e9c5c75",
   "metadata": {},
   "source": [
    "# Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "951619a6-d686-41bc-b9fe-185cd967787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine train_df with features_df and stores_df to enrich your sales data.\n",
    "# Merge train with features on Store, Date\n",
    "\n",
    "train_features = pd.merge(train_df, features_df, on=['Store', 'Date'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b411c6d3-5465-4714-af4b-e7e3100ca2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with stores info on Store\n",
    "full_df = pd.merge(train_features, stores_df, on='Store', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c748604-49e4-4cb9-aa3e-4be386ea55ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store  Dept        Date  Weekly_Sales  IsHoliday_x  Temperature  \\\n",
      "0      1     1  2010-02-05      24924.50        False        42.31   \n",
      "1      1     1  2010-02-12      46039.49         True        38.51   \n",
      "2      1     1  2010-02-19      41595.55        False        39.93   \n",
      "3      1     1  2010-02-26      19403.54        False        46.63   \n",
      "4      1     1  2010-03-05      21827.90        False        46.50   \n",
      "\n",
      "   Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5  \\\n",
      "0       2.572        NaN        NaN        NaN        NaN        NaN   \n",
      "1       2.548        NaN        NaN        NaN        NaN        NaN   \n",
      "2       2.514        NaN        NaN        NaN        NaN        NaN   \n",
      "3       2.561        NaN        NaN        NaN        NaN        NaN   \n",
      "4       2.625        NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "          CPI  Unemployment  IsHoliday_y Type    Size  \n",
      "0  211.096358         8.106        False    A  151315  \n",
      "1  211.242170         8.106         True    A  151315  \n",
      "2  211.289143         8.106        False    A  151315  \n",
      "3  211.319643         8.106        False    A  151315  \n",
      "4  211.350143         8.106        False    A  151315  \n"
     ]
    }
   ],
   "source": [
    "# Check result\n",
    "print(full_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40edaa99-2a01-42a6-999b-f7f620e0ccb8",
   "metadata": {},
   "source": [
    "# Concatenate Data (multiple weeks, simulate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbd126d5-4f8c-4759-96b7-737c200aa8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example (simulate by splitting train_df)\n",
    "df1 = train_df.iloc[:20000]\n",
    "df2 = train_df.iloc[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a683075-54cd-4200-a82e-24dc70d1d622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(421570, 5)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate\n",
    "concat_df = pd.concat([df1, df2], axis=0)\n",
    "print(concat_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e869c0fa-3768-44df-971e-c3286443725e",
   "metadata": {},
   "source": [
    "# GroupBy Analysis on Merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41c69b16-2cad-4c0b-855d-8ec12e2b5ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type\n",
      "A    4.331015e+09\n",
      "B    2.000701e+09\n",
      "C    4.055035e+08\n",
      "Name: Weekly_Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Sales by Store Type\n",
    "\n",
    "sales_by_type = full_df.groupby('Type')['Weekly_Sales'].sum()\n",
    "print(sales_by_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2999bd4-d7f5-4560-a3d2-6918562519d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dept   Size  Weekly_Sales\n",
      "0     1  34875   9774.553077\n",
      "1     1  37392   7328.621049\n",
      "2     1  39690   6559.257832\n",
      "3     1  39910   7104.485198\n",
      "4     1  41062   7549.109021\n"
     ]
    }
   ],
   "source": [
    "#Department performance by store size\n",
    "\n",
    "dept_by_size = full_df.groupby(['Dept', 'Size'])['Weekly_Sales'].mean().reset_index()\n",
    "print(dept_by_size.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c88ddb2-05c5-4e00-816f-88306768c2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Store  Dept  Weekly_Sales\n",
      "8        1     1      57258.43\n",
      "46       1     1      55931.23\n",
      "63       1     1      50510.31\n",
      "106      1     1      54060.10\n",
      "113      1     1      57592.12\n"
     ]
    }
   ],
   "source": [
    "#Filter: High-sales departments\n",
    "\n",
    "high_sales = full_df[full_df['Weekly_Sales'] > 50000]\n",
    "print(high_sales[['Store', 'Dept', 'Weekly_Sales']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6632ca-4cdc-42a4-ae55-97c5d54410d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
