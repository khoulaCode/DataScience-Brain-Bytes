{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2896dbec-380b-46a4-b807-0437538f39fb",
   "metadata": {},
   "source": [
    "#### pandas → load and preprocess the dataset.\n",
    "\n",
    "#### numpy → arrays, handle indices and similarity scores.\n",
    "\n",
    "#### TfidfVectorizer (sklearn) → convert headlines and queries into numeric vectors.\n",
    "\n",
    "#### scipy.sparse → efficiently store the TF-IDF vectors.\n",
    "\n",
    "#### linear_kernel (sklearn) → compute cosine similarity between query and headlines.\n",
    "\n",
    "#### joblib → save/load the vectorizer and TF-IDF matrix for future searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d650bb3-14fb-4681-a9fe-61f8b2e8cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from scipy import sparse\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f8016e-7ffb-4c99-a9cb-bcc8f45fec90",
   "metadata": {},
   "source": [
    "## News Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c70db65-0341-407e-857a-8b259763c32a",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Filters to your 4 categories.\n",
    "\n",
    "Keeps only headline and category.\n",
    "\n",
    "Balances dataset to 1,000 per category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8135b0-7c08-496f-83c0-79f7ebfb977b",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization\n",
    "\n",
    "Trains TF-IDF on headlines.\n",
    "\n",
    "Uses unigrams and bigrams for better matching.\n",
    "\n",
    "## Search\n",
    "\n",
    "Converts a free-text query into TF-IDF.\n",
    "\n",
    "Computes cosine similarity with all headlines.\n",
    "\n",
    "Returns top 10 results with headline, category, similarity_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438cbfd8-17fc-40d5-8dc1-357db44d9519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            headline  category  \\\n",
      "0  Donald Trump Still Won't Say If He'll Accept E...  POLITICS   \n",
      "1  Doug Lamborn Midterm Election Results: Republi...  POLITICS   \n",
      "2  Colorado Senate Election Results: Cory Gardner...  POLITICS   \n",
      "3  Rick Larsen Midterm Election Results: Larsen D...  POLITICS   \n",
      "4  Cathy McMorris Rodgers Midterm Election Result...  POLITICS   \n",
      "5               Trump’s Foreign Policy Is A Disaster  POLITICS   \n",
      "6    What the Government Shutdown Means to Travelers    TRAVEL   \n",
      "7    Americans Can't Wait Until The Election Is Over  POLITICS   \n",
      "8  Top U.S. Diplomat In China Quits Over Donald T...  POLITICS   \n",
      "9  NCAA’s New Sexual Violence Policy Underwhelmin...    SPORTS   \n",
      "\n",
      "   similarity_score  \n",
      "0          0.336693  \n",
      "1          0.280195  \n",
      "2          0.276106  \n",
      "3          0.259444  \n",
      "4          0.256840  \n",
      "5          0.177884  \n",
      "6          0.154296  \n",
      "7          0.140693  \n",
      "8          0.133345  \n",
      "9          0.130793  \n"
     ]
    }
   ],
   "source": [
    "# --- Parameters ---\n",
    "TARGET_CATEGORIES = [\"POLITICS\", \"TRAVEL\", \"SPORTS\", \"HOME & LIVING\"]\n",
    "TARGET_PER_CAT = 1000\n",
    "\n",
    "# --- 1. Load and preprocess dataset ---\n",
    "def load_news_dataset(file_path):\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "    df = df[['category', 'headline']]\n",
    "    df = df[df['category'].isin(TARGET_CATEGORIES)]\n",
    "    df = df.dropna(subset=['headline']).drop_duplicates(subset=['headline'])\n",
    "    \n",
    "    # Balance to TARGET_PER_CAT per category\n",
    "    balanced_frames = []\n",
    "    for cat in TARGET_CATEGORIES:\n",
    "        subset = df[df['category'] == cat].sample(frac=1, random_state=42)\n",
    "        if len(subset) >= TARGET_PER_CAT:\n",
    "            subset = subset.head(TARGET_PER_CAT)\n",
    "        balanced_frames.append(subset)\n",
    "    \n",
    "    balanced = pd.concat(balanced_frames, ignore_index=True)\n",
    "    return balanced.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. TF-IDF Vectorization ---\n",
    "def build_tfidf_index(df):\n",
    "    vectorizer = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1,2), norm='l2')\n",
    "    X = vectorizer.fit_transform(df['headline'])\n",
    "    return vectorizer, X\n",
    "\n",
    "\n",
    "# --- 3. Search Function ---\n",
    "def search(query, vectorizer, X, df, top_k=10):\n",
    "    q_vec = vectorizer.transform([query])\n",
    "    sims = linear_kernel(q_vec, X).ravel()\n",
    "    top_idx = np.argsort(-sims)[:top_k]\n",
    "    results = df.iloc[top_idx].copy()\n",
    "    results['similarity_score'] = sims[top_idx]\n",
    "    return results[['headline', 'category', 'similarity_score']].reset_index(drop=True)\n",
    "\n",
    "# --- 4. Save \n",
    "def save_artifacts(vectorizer, X, df, prefix=\"news\"):\n",
    "    joblib.dump(vectorizer, f\"{prefix}_tfidf_vectorizer.joblib\")\n",
    "    sparse.save_npz(f\"{prefix}_tfidf_matrix.npz\", X)\n",
    "    df.to_csv(f\"{prefix}_index.csv\", index=False)\n",
    "\n",
    "def load_artifacts(prefix=\"news\"):\n",
    "    vectorizer = joblib.load(f\"{prefix}_tfidf_vectorizer.joblib\")\n",
    "    X = sparse.load_npz(f\"{prefix}_tfidf_matrix.npz\")\n",
    "    df = pd.read_csv(f\"{prefix}_index.csv\")\n",
    "    return vectorizer, X, df\n",
    "\n",
    "# --- Example Usage : ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Load & preprocess dataset\n",
    "    df = load_news_dataset(\"News_Category_Dataset_v3.json\")\n",
    "    \n",
    "    # Build TF-IDF index\n",
    "    vectorizer, X = build_tfidf_index(df)\n",
    "    \n",
    "    # Optional: save artifacts for later\n",
    "    save_artifacts(vectorizer, X, df)\n",
    "    \n",
    "    # Perform a search\n",
    "    query = \"election results and government policy\"\n",
    "    results = search(query, vectorizer, X, df, top_k=10)\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486ffc4a-89a0-49b4-99ca-45da2302d9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
