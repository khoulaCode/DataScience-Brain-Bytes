{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd93b2c-2675-4473-8d4f-5fda82df8e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\bbuser\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\bbuser\\anaconda3\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\bbuser\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\bbuser\\anaconda3\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\bbuser\\anaconda3\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\bbuser\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\bbuser\\anaconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bbuser\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bbuser\\anaconda3\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bbuser\\anaconda3\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\bbuser\\anaconda3\\lib\\site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\bbuser\\anaconda3\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bbuser\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bbuser\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "116bb46b-bf73-4376-9421-b7912757e25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total characters in text: 50000\n",
      " Unique characters: 42\n",
      " Number of sequences: 9992\n",
      "X shape: torch.Size([9992, 40])\n",
      "y shape: torch.Size([9992])\n",
      " Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|████████████████████████████████████████████████████████████████████| 157/157 [00:11<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1, Loss: 2.4719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|████████████████████████████████████████████████████████████████████| 157/157 [00:10<00:00, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 2, Loss: 2.0850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|████████████████████████████████████████████████████████████████████| 157/157 [00:11<00:00, 13.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 3, Loss: 1.9615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|████████████████████████████████████████████████████████████████████| 157/157 [00:11<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 4, Loss: 1.8799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|████████████████████████████████████████████████████████████████████| 157/157 [00:11<00:00, 14.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 5, Loss: 1.8154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|████████████████████████████████████████████████████████████████████| 157/157 [00:10<00:00, 14.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 6, Loss: 1.7504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|████████████████████████████████████████████████████████████████████| 157/157 [00:11<00:00, 13.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 7, Loss: 1.7041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|████████████████████████████████████████████████████████████████████| 157/157 [00:10<00:00, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 8, Loss: 1.6560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|████████████████████████████████████████████████████████████████████| 157/157 [00:10<00:00, 14.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 9, Loss: 1.6216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|███████████████████████████████████████████████████████████████████| 157/157 [00:11<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10, Loss: 1.5794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|███████████████████████████████████████████████████████████████████| 157/157 [00:11<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11, Loss: 1.5476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|███████████████████████████████████████████████████████████████████| 157/157 [00:11<00:00, 13.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12, Loss: 1.5291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|███████████████████████████████████████████████████████████████████| 157/157 [00:11<00:00, 13.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13, Loss: 1.5003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|███████████████████████████████████████████████████████████████████| 157/157 [00:10<00:00, 14.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14, Loss: 1.4802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|███████████████████████████████████████████████████████████████████| 157/157 [00:11<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15, Loss: 1.4536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|███████████████████████████████████████████████████████████████████| 157/157 [00:10<00:00, 14.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16, Loss: 1.4351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|███████████████████████████████████████████████████████████████████| 157/157 [00:11<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17, Loss: 1.4116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|███████████████████████████████████████████████████████████████████| 157/157 [00:11<00:00, 13.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18, Loss: 1.3987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|███████████████████████████████████████████████████████████████████| 157/157 [00:10<00:00, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19, Loss: 1.3801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|███████████████████████████████████████████████████████████████████| 157/157 [00:11<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20, Loss: 1.3644\n",
      "\n",
      "Sample generated text:\n",
      "once the beamun the mill hern, and bace the kery one atked on the s over the cans.  i sleamly,s nead.\n",
      "s on tions, whinnin ull gilver ack, and pring in be ars; thing it he reet in the say in the ring, houn\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open(\"cleaned_merged_fairy_tales_without_eos.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read().lower()\n",
    "\n",
    "# smaller subset of text for faster training\n",
    "max_length = 50000   \n",
    "text = text[:max_length]\n",
    "\n",
    "# Create vocabulary\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(f\" Total characters in text: {len(text)}\")\n",
    "print(f\" Unique characters: {vocab_size}\")\n",
    "\n",
    "# Character \n",
    "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# Encode text\n",
    "encoded_text = [char_to_idx[c] for c in text]\n",
    "\n",
    "\n",
    "seq_length = 40\n",
    "step = 5   \n",
    "\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for i in range(0, len(encoded_text) - seq_length, step):\n",
    "    X_data.append(encoded_text[i:i+seq_length])\n",
    "    y_data.append(encoded_text[i+seq_length])\n",
    "\n",
    "X = torch.tensor(X_data, dtype=torch.long)\n",
    "y = torch.tensor(y_data, dtype=torch.long)\n",
    "\n",
    "print(f\" Number of sequences: {len(X_data)}\")\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = CharDataset(X, y)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=0,    \n",
    "    pin_memory=False  \n",
    ")\n",
    "\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers=1):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out[:, -1, :])  # output from last timestep\n",
    "        return out, hidden\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\" Using device: {device}\")\n",
    "\n",
    "hidden_size = 64  # smaller hidden size = faster training\n",
    "model = CharRNN(vocab_size, hidden_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\" Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Text generation\n",
    "\n",
    "def generate_text(model, start_text=\"once\", length=100):\n",
    "    model.eval()\n",
    "    input_seq = torch.tensor([[char_to_idx[c] for c in start_text]], dtype=torch.long).to(device)\n",
    "    hidden = None\n",
    "    result = start_text\n",
    "\n",
    "    for _ in range(length):\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        next_char_idx = torch.multinomial(probs, num_samples=1).item()\n",
    "        next_char = idx_to_char[next_char_idx]\n",
    "        result += next_char\n",
    "        input_seq = torch.tensor([[next_char_idx]], dtype=torch.long).to(device)\n",
    "\n",
    "    return result\n",
    "\n",
    "print(\"\\nSample generated text:\")\n",
    "print(generate_text(model, \"once\", 200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6bdc3b-d583-4aaf-8a6d-250709a5da15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
