{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f04a35",
   "metadata": {},
   "source": [
    "# Handling-Overfitting-with-CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e9758",
   "metadata": {},
   "source": [
    "### Q1: How does adding dropout layers affect training vs validation accuracy?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789054e4",
   "metadata": {},
   "source": [
    "Adding dropout reduced training accuracy but improved validation accuracy stability. This means the model overfits less and generalizes better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccba13f",
   "metadata": {},
   "source": [
    "### Q2: Does early stopping prevent wasted training time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbaf4a8",
   "metadata": {},
   "source": [
    "Yes, training stops early when validation loss stops improving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81753a9b",
   "metadata": {},
   "source": [
    "### Q3: Can L2 weight regularization improve generalization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f8eaf7",
   "metadata": {},
   "source": [
    "Yes, it keeps weights small and smooths the decision boundary, improving validation accuracy slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24557284",
   "metadata": {},
   "source": [
    "### Q4: How does model depth affect overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7523bb8",
   "metadata": {},
   "source": [
    "Deeper networks fit training data faster but overfit more; shallower ones are more stable but less accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f65bc",
   "metadata": {},
   "source": [
    "### Data & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb709aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import numpy as np\n",
    "\n",
    "# data\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype(\"float32\")/255.0\n",
    "x_test  = x_test.astype(\"float32\")/255.0\n",
    "y_train = y_train.flatten(); y_test = y_test.flatten()\n",
    "\n",
    "input_shape = (32,32,3)\n",
    "num_classes = 10\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1bbf65",
   "metadata": {},
   "source": [
    "### Baseline (no regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7a198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python313\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "391/391 - 13s - 32ms/step - accuracy: 0.3212 - loss: 1.9008 - val_accuracy: 0.3719 - val_loss: 1.7317\n",
      "Epoch 2/15\n",
      "391/391 - 16s - 42ms/step - accuracy: 0.3998 - loss: 1.6791 - val_accuracy: 0.4229 - val_loss: 1.6185\n",
      "Epoch 3/15\n",
      "391/391 - 11s - 29ms/step - accuracy: 0.4334 - loss: 1.5853 - val_accuracy: 0.4521 - val_loss: 1.5322\n",
      "Epoch 4/15\n",
      "391/391 - 13s - 32ms/step - accuracy: 0.4494 - loss: 1.5374 - val_accuracy: 0.4586 - val_loss: 1.5144\n",
      "Epoch 5/15\n",
      "391/391 - 12s - 30ms/step - accuracy: 0.4689 - loss: 1.4877 - val_accuracy: 0.4610 - val_loss: 1.5164\n",
      "Epoch 6/15\n",
      "391/391 - 13s - 32ms/step - accuracy: 0.4810 - loss: 1.4615 - val_accuracy: 0.4613 - val_loss: 1.5194\n",
      "Epoch 7/15\n",
      "391/391 - 13s - 33ms/step - accuracy: 0.4923 - loss: 1.4252 - val_accuracy: 0.4727 - val_loss: 1.4829\n",
      "Epoch 8/15\n",
      "391/391 - 12s - 31ms/step - accuracy: 0.5008 - loss: 1.4007 - val_accuracy: 0.4887 - val_loss: 1.4258\n",
      "Epoch 9/15\n",
      "391/391 - 12s - 31ms/step - accuracy: 0.5078 - loss: 1.3753 - val_accuracy: 0.4849 - val_loss: 1.4574\n",
      "Epoch 10/15\n",
      "391/391 - 12s - 31ms/step - accuracy: 0.5153 - loss: 1.3550 - val_accuracy: 0.4954 - val_loss: 1.4163\n",
      "Epoch 11/15\n",
      "391/391 - 13s - 32ms/step - accuracy: 0.5241 - loss: 1.3273 - val_accuracy: 0.4963 - val_loss: 1.4337\n",
      "Epoch 12/15\n",
      "391/391 - 12s - 32ms/step - accuracy: 0.5342 - loss: 1.3040 - val_accuracy: 0.4933 - val_loss: 1.4217\n",
      "Epoch 13/15\n",
      "391/391 - 12s - 31ms/step - accuracy: 0.5412 - loss: 1.2827 - val_accuracy: 0.5043 - val_loss: 1.4101\n",
      "Epoch 14/15\n",
      "391/391 - 11s - 29ms/step - accuracy: 0.5482 - loss: 1.2647 - val_accuracy: 0.4964 - val_loss: 1.4557\n",
      "Epoch 15/15\n",
      "391/391 - 11s - 27ms/step - accuracy: 0.5534 - loss: 1.2474 - val_accuracy: 0.4998 - val_loss: 1.4141\n",
      "Baseline test acc: 0.5\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Flatten(input_shape=input_shape),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=15, batch_size=128,\n",
    "                 validation_data=(x_test, y_test), verbose=2)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "results[\"baseline\"] = float(test_acc)\n",
    "print(\"Baseline test acc:\", round(test_acc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7f60ea",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d83306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "391/391 - 14s - 35ms/step - accuracy: 0.2083 - loss: 2.1076 - val_accuracy: 0.3012 - val_loss: 1.9636\n",
      "Epoch 2/15\n",
      "391/391 - 13s - 32ms/step - accuracy: 0.2420 - loss: 2.0058 - val_accuracy: 0.3112 - val_loss: 1.9376\n",
      "Epoch 3/15\n",
      "391/391 - 13s - 33ms/step - accuracy: 0.2592 - loss: 1.9736 - val_accuracy: 0.3139 - val_loss: 1.9369\n",
      "Epoch 4/15\n",
      "391/391 - 13s - 32ms/step - accuracy: 0.2613 - loss: 1.9664 - val_accuracy: 0.3104 - val_loss: 1.9361\n",
      "Epoch 5/15\n",
      "391/391 - 13s - 33ms/step - accuracy: 0.2698 - loss: 1.9468 - val_accuracy: 0.3298 - val_loss: 1.9211\n",
      "Epoch 6/15\n",
      "391/391 - 10s - 26ms/step - accuracy: 0.2791 - loss: 1.9322 - val_accuracy: 0.3398 - val_loss: 1.9033\n",
      "Epoch 7/15\n",
      "391/391 - 12s - 30ms/step - accuracy: 0.2875 - loss: 1.9192 - val_accuracy: 0.3276 - val_loss: 1.9278\n",
      "Epoch 8/15\n",
      "391/391 - 21s - 54ms/step - accuracy: 0.2936 - loss: 1.9054 - val_accuracy: 0.3476 - val_loss: 1.9121\n",
      "Epoch 9/15\n",
      "391/391 - 10s - 25ms/step - accuracy: 0.2974 - loss: 1.8907 - val_accuracy: 0.3469 - val_loss: 1.9023\n",
      "Epoch 10/15\n",
      "391/391 - 10s - 25ms/step - accuracy: 0.3015 - loss: 1.8852 - val_accuracy: 0.3429 - val_loss: 1.8939\n",
      "Epoch 11/15\n",
      "391/391 - 14s - 35ms/step - accuracy: 0.3018 - loss: 1.8845 - val_accuracy: 0.3435 - val_loss: 1.9114\n",
      "Epoch 12/15\n",
      "391/391 - 20s - 52ms/step - accuracy: 0.3071 - loss: 1.8705 - val_accuracy: 0.3521 - val_loss: 1.8833\n",
      "Epoch 13/15\n",
      "391/391 - 13s - 32ms/step - accuracy: 0.3098 - loss: 1.8706 - val_accuracy: 0.3495 - val_loss: 1.8685\n",
      "Epoch 14/15\n",
      "391/391 - 13s - 33ms/step - accuracy: 0.3125 - loss: 1.8544 - val_accuracy: 0.3521 - val_loss: 1.8849\n",
      "Epoch 15/15\n",
      "391/391 - 20s - 50ms/step - accuracy: 0.3127 - loss: 1.8576 - val_accuracy: 0.3664 - val_loss: 1.8709\n",
      "Dropout test acc: 0.366\n"
     ]
    }
   ],
   "source": [
    "model_do = keras.Sequential([\n",
    "    layers.Flatten(input_shape=input_shape),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_do.compile(optimizer=\"adam\",\n",
    "                 loss=\"sparse_categorical_crossentropy\",\n",
    "                 metrics=[\"accuracy\"])\n",
    "\n",
    "hist_do = model_do.fit(x_train, y_train, epochs=15, batch_size=128,\n",
    "                       validation_data=(x_test, y_test), verbose=2)\n",
    "\n",
    "_, acc_do = model_do.evaluate(x_test, y_test, verbose=0)\n",
    "results[\"dropout\"] = float(acc_do)\n",
    "print(\"Dropout test acc:\", round(acc_do,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ba0eb8",
   "metadata": {},
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffda947c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "391/391 - 14s - 35ms/step - accuracy: 0.2004 - loss: 2.1302 - val_accuracy: 0.2699 - val_loss: 1.9781\n",
      "Epoch 2/30\n",
      "391/391 - 27s - 68ms/step - accuracy: 0.2390 - loss: 2.0182 - val_accuracy: 0.2998 - val_loss: 1.9398\n",
      "Epoch 3/30\n",
      "391/391 - 19s - 48ms/step - accuracy: 0.2588 - loss: 1.9771 - val_accuracy: 0.3283 - val_loss: 1.9063\n",
      "Epoch 4/30\n",
      "391/391 - 11s - 28ms/step - accuracy: 0.2686 - loss: 1.9444 - val_accuracy: 0.3056 - val_loss: 1.9624\n",
      "Epoch 5/30\n",
      "391/391 - 19s - 49ms/step - accuracy: 0.2790 - loss: 1.9308 - val_accuracy: 0.3262 - val_loss: 1.9478\n",
      "Epoch 6/30\n",
      "391/391 - 22s - 55ms/step - accuracy: 0.2813 - loss: 1.9288 - val_accuracy: 0.3390 - val_loss: 1.8923\n",
      "Epoch 7/30\n",
      "391/391 - 14s - 36ms/step - accuracy: 0.2821 - loss: 1.9098 - val_accuracy: 0.3337 - val_loss: 1.9189\n",
      "Epoch 8/30\n",
      "391/391 - 13s - 34ms/step - accuracy: 0.2876 - loss: 1.9063 - val_accuracy: 0.3537 - val_loss: 1.8978\n",
      "Epoch 9/30\n",
      "391/391 - 12s - 30ms/step - accuracy: 0.2907 - loss: 1.9015 - val_accuracy: 0.3493 - val_loss: 1.8935\n",
      "Dropout+EarlyStopping test acc: 0.339\n",
      "Best epoch: 9\n"
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_es = keras.Sequential([\n",
    "    layers.Flatten(input_shape=input_shape),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_es.compile(optimizer=\"adam\",\n",
    "                 loss=\"sparse_categorical_crossentropy\",\n",
    "                 metrics=[\"accuracy\"])\n",
    "\n",
    "hist_es = model_es.fit(x_train, y_train, epochs=30, batch_size=128,\n",
    "                       validation_data=(x_test, y_test),\n",
    "                       callbacks=[early_stop], verbose=2)\n",
    "\n",
    "_, acc_es = model_es.evaluate(x_test, y_test, verbose=0)\n",
    "results[\"dropout+earlystop\"] = float(acc_es)\n",
    "print(\"Dropout+EarlyStopping test acc:\", round(acc_es,3))\n",
    "print(\"Best epoch:\", len(hist_es.history[\"loss\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f96f1",
   "metadata": {},
   "source": [
    "### L2 Weight Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e826d9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "391/391 - 13s - 34ms/step - accuracy: 0.3246 - loss: 2.3939 - val_accuracy: 0.3771 - val_loss: 2.0045\n",
      "Epoch 2/15\n",
      "391/391 - 12s - 30ms/step - accuracy: 0.3942 - loss: 1.8892 - val_accuracy: 0.3746 - val_loss: 1.8915\n",
      "Epoch 3/15\n",
      "391/391 - 14s - 35ms/step - accuracy: 0.4189 - loss: 1.7643 - val_accuracy: 0.4444 - val_loss: 1.6983\n",
      "Epoch 4/15\n",
      "391/391 - 14s - 36ms/step - accuracy: 0.4366 - loss: 1.7033 - val_accuracy: 0.4361 - val_loss: 1.6892\n",
      "Epoch 5/15\n",
      "391/391 - 14s - 35ms/step - accuracy: 0.4452 - loss: 1.6695 - val_accuracy: 0.4522 - val_loss: 1.6425\n",
      "Epoch 6/15\n",
      "391/391 - 13s - 34ms/step - accuracy: 0.4577 - loss: 1.6314 - val_accuracy: 0.4622 - val_loss: 1.6187\n",
      "Epoch 7/15\n",
      "391/391 - 14s - 35ms/step - accuracy: 0.4634 - loss: 1.6198 - val_accuracy: 0.4318 - val_loss: 1.6993\n",
      "Epoch 8/15\n",
      "391/391 - 14s - 35ms/step - accuracy: 0.4708 - loss: 1.5931 - val_accuracy: 0.4794 - val_loss: 1.5719\n",
      "Epoch 9/15\n",
      "391/391 - 11s - 29ms/step - accuracy: 0.4732 - loss: 1.5853 - val_accuracy: 0.4525 - val_loss: 1.6321\n",
      "Epoch 10/15\n",
      "391/391 - 11s - 27ms/step - accuracy: 0.4771 - loss: 1.5738 - val_accuracy: 0.4754 - val_loss: 1.5879\n",
      "Epoch 11/15\n",
      "391/391 - 12s - 32ms/step - accuracy: 0.4823 - loss: 1.5610 - val_accuracy: 0.4533 - val_loss: 1.6265\n",
      "Epoch 12/15\n",
      "391/391 - 16s - 41ms/step - accuracy: 0.4835 - loss: 1.5602 - val_accuracy: 0.4508 - val_loss: 1.6767\n",
      "Epoch 13/15\n",
      "391/391 - 17s - 44ms/step - accuracy: 0.4883 - loss: 1.5466 - val_accuracy: 0.4773 - val_loss: 1.5620\n",
      "Epoch 14/15\n",
      "391/391 - 13s - 34ms/step - accuracy: 0.4917 - loss: 1.5316 - val_accuracy: 0.4810 - val_loss: 1.5546\n",
      "Epoch 15/15\n",
      "391/391 - 13s - 34ms/step - accuracy: 0.4913 - loss: 1.5378 - val_accuracy: 0.4829 - val_loss: 1.5685\n",
      "L2 test acc: 0.483\n"
     ]
    }
   ],
   "source": [
    "model_l2 = keras.Sequential([\n",
    "    layers.Flatten(input_shape=input_shape),\n",
    "    layers.Dense(512, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_l2.compile(optimizer=\"adam\",\n",
    "                 loss=\"sparse_categorical_crossentropy\",\n",
    "                 metrics=[\"accuracy\"])\n",
    "\n",
    "hist_l2 = model_l2.fit(x_train, y_train, epochs=15, batch_size=128,\n",
    "                       validation_data=(x_test, y_test), verbose=2)\n",
    "\n",
    "_, acc_l2 = model_l2.evaluate(x_test, y_test, verbose=0)\n",
    "results[\"l2\"] = float(acc_l2)\n",
    "print(\"L2 test acc:\", round(acc_l2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211fe680",
   "metadata": {},
   "source": [
    "### Report validation accuracy improvements with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b67349d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary (higher is better) ===\n",
      "baseline             -> 0.500\n",
      "dropout              -> 0.366\n",
      "dropout+earlystop    -> 0.339\n",
      "l2                   -> 0.483\n",
      "\n",
      "Notes:\n",
      "- Dropout: usually lowers train acc but helps val acc (less overfitting).\n",
      "- EarlyStopping: stops at best epoch, saves time.\n",
      "- L2: keeps weights small, improves generalization a bit.\n",
      "- Depth: deeper can overfit; use dropout/L2/ES to control.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Summary (higher is better) ===\")\n",
    "for k,v in results.items():\n",
    "    print(f\"{k:20s} -> {v:.3f}\")\n",
    "\n",
    "print(\"\\nNotes:\")\n",
    "print(\"- Dropout: usually lowers train acc but helps val acc (less overfitting).\")\n",
    "print(\"- EarlyStopping: stops at best epoch, saves time.\")\n",
    "print(\"- L2: keeps weights small, improves generalization a bit.\")\n",
    "print(\"- Depth: deeper can overfit; use dropout/L2/ES to control.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e6f4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
