{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34953e19",
   "metadata": {},
   "source": [
    "# IMDb Movie Reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d4defd-f000-44b4-96e6-5d65f17cbe31",
   "metadata": {},
   "source": [
    "## Import the Liabraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f890611e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bbuser\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bbuser\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\bbuser\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "390ef3c5-197a-419e-9764-127d2094b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c7fb5-53b1-4d85-8f16-4daf166164ce",
   "metadata": {},
   "source": [
    "## Load IMDb Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee28a83a-af99-4bcb-8a54-2ecc2c4b18df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def load_reviews_from_dir(directory, label):\n",
    "    files = glob.glob(directory + \"/*.txt\")\n",
    "    data = []\n",
    "    for f in files:\n",
    "        with open(f, encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "            data.append([text, label])\n",
    "    return pd.DataFrame(data, columns=['review', 'sentiment'])\n",
    "\n",
    "train_pos = r\"C:\\Users\\bbuser\\Desktop\\Jupyter\\aclImdb\\train\\pos\"\n",
    "train_neg = r\"C:\\Users\\bbuser\\Desktop\\Jupyter\\aclImdb\\train\\neg\"\n",
    "\n",
    "\n",
    "df_train = pd.concat([\n",
    "    load_reviews_from_dir(train_pos, 'positive'),\n",
    "    load_reviews_from_dir(train_neg, 'negative')\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44b24c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...  positive\n",
       "1  Homelessness (or Houselessness as George Carli...  positive\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...  positive\n",
       "3  This is easily the most underrated film inn th...  positive\n",
       "4  This is not the typical Mel Brooks film. It wa...  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2b4b234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fa447a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=25000, step=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ab8d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a Subset of Reviews\n",
    "df_sample = df_train.sample(n=10000, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7dabbe-692d-425d-bae3-c567b2a462b4",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba9c7674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def clean_review(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "    # Remove URLs and emails\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "\n",
    "    # Remove punctuation, numbers, and non-letters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Remove stopwords & short tokens, lemmatize\n",
    "    cleaned_tokens = [\n",
    "        lemmatizer.lemmatize(word)\n",
    "        for word in tokens\n",
    "        if word not in stop_words and len(word) > 2\n",
    "    ]\n",
    "\n",
    "    # Join tokens back to string\n",
    "    return \" \".join(cleaned_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce5e7fd4-8385-40ca-94b8-cd1545eff9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbuser\\AppData\\Local\\Temp\\ipykernel_17984\\1226166216.py:8: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    }
   ],
   "source": [
    "#Apply Cleaning to Dataset\n",
    "df_sample['cleaned_review'] = df_sample['review'].apply(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3161fb6-cc15-44cd-9303-1332f33938af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In Panic In The Streets Richard Widmark plays ...</td>\n",
       "      <td>panic street richard widmark play navy doctor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you ask me the first one was really better ...</td>\n",
       "      <td>ask first one really better one look sarah rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am a big fan a Faerie Tale Theatre and I've ...</td>\n",
       "      <td>big fan faerie tale theatre ive seen one best ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I just finished reading a book about Dillinger...</td>\n",
       "      <td>finished reading book dillinger movie horribly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greg Davis and Bryan Daly take some crazed sta...</td>\n",
       "      <td>greg davis bryan daly take crazed statement te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  In Panic In The Streets Richard Widmark plays ...   \n",
       "1  If you ask me the first one was really better ...   \n",
       "2  I am a big fan a Faerie Tale Theatre and I've ...   \n",
       "3  I just finished reading a book about Dillinger...   \n",
       "4  Greg Davis and Bryan Daly take some crazed sta...   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  panic street richard widmark play navy doctor ...  \n",
       "1  ask first one really better one look sarah rea...  \n",
       "2  big fan faerie tale theatre ive seen one best ...  \n",
       "3  finished reading book dillinger movie horribly...  \n",
       "4  greg davis bryan daly take crazed statement te...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview Cleaned Data\n",
    "df_sample[['review', 'cleaned_review']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730062a-e291-4eb1-8104-5984625b3e55",
   "metadata": {},
   "source": [
    "### Save Cleaned Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66462e26-0e3e-42b3-9681-03c9f4f55396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_csv(\"cleaned_imdb_sample.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
