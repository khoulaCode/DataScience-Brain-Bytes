{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5510ad55-124a-47f0-ba69-9ea2490eb222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cf04dab-d66e-44eb-bab1-a7c550f126ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\bbuser\\Desktop\\aclImdb_cleaned\\imdb_train_cleaned_sample.csv\"\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f10243e3-e23f-4c1c-989e-188d25ae5249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['cleaned_review', 'label']].dropna()\n",
    "if df['label'].dtype == object:\n",
    "    df['label'] = df['label'].map({'neg': 0, 'pos': 1}).astype(int)\n",
    "\n",
    "x_text = df['cleaned_review'].astype(str)\n",
    "y = df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a541b4d-7c3b-460f-ba15-8524e435acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_text, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93e2de3f-06ea-4e3a-ae23-e5a940140e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=3, ngram_range=(1, 2), max_features=50000)\n",
    "x_train_tf = vectorizer.fit_transform(x_train)\n",
    "x_test_tf  = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0c9309f-5628-4d45-a0f3-c9093c69bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"logreg\": LogisticRegression(max_iter=2000, n_jobs=None),\n",
    "    \"dtree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"rf\": RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "849fe7f3-4e22-4084-a2ca-facc0b61d688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LOGREG — classification report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.88      1000\n",
      "    positive       0.87      0.90      0.89      1000\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.89      0.89      0.89      2000\n",
      "weighted avg       0.89      0.89      0.89      2000\n",
      "\n",
      "\n",
      "=== DTREE — classification report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.70      0.70      1000\n",
      "    positive       0.70      0.70      0.70      1000\n",
      "\n",
      "    accuracy                           0.70      2000\n",
      "   macro avg       0.70      0.70      0.70      2000\n",
      "weighted avg       0.70      0.70      0.70      2000\n",
      "\n",
      "\n",
      "=== RF — classification report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87      1000\n",
      "    positive       0.87      0.85      0.86      1000\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "\n",
      "=== Comparison table (higher is better) ===\n",
      " model  accuracy  precision  recall       f1\n",
      "logreg    0.8860   0.873308   0.903 0.887906\n",
      "    rf    0.8635   0.872057   0.852 0.861912\n",
      " dtree    0.7030   0.702595   0.704 0.703297\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "preds = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(x_train_tf, y_train)\n",
    "    y_pred = model.predict(x_test_tf)\n",
    "    preds[name] = y_pred\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"binary\", pos_label=1)\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": p,\n",
    "        \"recall\": r,\n",
    "        \"f1\": f1\n",
    "    })\n",
    "\n",
    "    print(f\"\\n=== {name.upper()} — classification report ===\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"negative\", \"positive\"]))\n",
    "\n",
    "metrics_df = pd.DataFrame(rows).sort_values(\"f1\", ascending=False).reset_index(drop=True)\n",
    "print(\"\\n=== Comparison table (higher is better) ===\")\n",
    "print(metrics_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59e2d66c-94e9-46b1-8ccd-ec0d4cf21834",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_idx = np.random.RandomState(42).choice(len(x_test), size=5, replace=False)\n",
    "example_df = pd.DataFrame({\n",
    "    \"cleaned_review\": x_test.iloc[ex_idx].values,\n",
    "    \"true\": [\"positive\" if t == 1 else \"negative\" for t in y_test.iloc[ex_idx].values],\n",
    "    \"logreg\": [\"positive\" if p == 1 else \"negative\" for p in preds[\"logreg\"][ex_idx]],\n",
    "    \"dtree\":  [\"positive\" if p == 1 else \"negative\" for p in preds[\"dtree\"][ex_idx]],\n",
    "    \"rf\":     [\"positive\" if p == 1 else \"negative\" for p in preds[\"rf\"][ex_idx]],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a028088-4b8f-48e4-a7b7-bf7f4ba832ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Example predictions (5 samples) ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     cleaned_review     true   logreg    dtree       rf\n",
      "                                                                                                                                                                                                                                                                                                                                       mystery men one movie get funnier time naive innocence niceness character become part family culture quote character often favorite film last two year kid three love film great acting comedy love galaxy quest monty python flick okay talking intellectual family bonding positive positive positive positive\n",
      "                               show dull lame basically rip sort various thing order make original first animation ugly johnny hideous everyone annoying twin look like teen female dexters dexter lab johnny almost like intelligent male dee dee also dexter lab secondly plot painfully lame making hard follow gag corny nothing really make feel compelled laugh little bit especially try funny saw two episode alone turned third whole theme song start ripping tune green day american idiot big fan band find really dumb would take opening melody subtly change order make case point big fat ugly bore negative negative positive negative\n",
      "                                                                                                                       interesting hardly scientific evidence movie provides point basicly jew cancer stupid lame almost laughable know happened era important nah imagine german even horrid time would like believe movie compare riefenstahl triumf willens movie impressed silly garbage best part scene one time favorite jew announcer eloquently keep reminding lorre play child molester murderer eye film maker depraved mind huh know hitler favorite movie right plain stupid even nazi propaganda genre negative negative negative negative\n",
      "                                                       anyone wish get impression soviet view modern russian history monumental film treasure story start turn century yellowish sepia colour old photograph improves black white middle century full colour story approach modern time story focus boy remote siberian village marked arrival arrest anarchist czarist era later join bolshevik revolution brings soviet communism village son local beauty fight german second world war return village oil industry take treated soviet economic idealism film long slow utterly logic well made seen three part positive positive positive positive\n",
      "early group suspiciously old looking teen maniac stalking around yes slasherville movie called prank called prank faintest idea unless idea great prank repeatedly hit someone dinner baseball bat balance great prank fact quite rubbish prank truth told film concern group teenager tasked cleaning decommissioned dormitory become aware psychopath loose combat development split wander dark end tear prank badly made slasher movie dvd release viewed vipco one appears cut fair bit violence make dvd even pointless let face slasher movie shorn violence waste time slasher film video nasty completists negative negative positive negative\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Example predictions (5 samples) ===\")\n",
    "print(example_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61ab741f-3cc1-4a33-84f8-9ec4a26cee54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>true</th>\n",
       "      <th>logreg</th>\n",
       "      <th>dtree</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mystery men one movie get funnier time naive i...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>show dull lame basically rip sort various thin...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interesting hardly scientific evidence movie p...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anyone wish get impression soviet view modern ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>early group suspiciously old looking teen mani...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cleaned_review      true    logreg  \\\n",
       "0  mystery men one movie get funnier time naive i...  positive  positive   \n",
       "1  show dull lame basically rip sort various thin...  negative  negative   \n",
       "2  interesting hardly scientific evidence movie p...  negative  negative   \n",
       "3  anyone wish get impression soviet view modern ...  positive  positive   \n",
       "4  early group suspiciously old looking teen mani...  negative  negative   \n",
       "\n",
       "      dtree        rf  \n",
       "0  positive  positive  \n",
       "1  positive  negative  \n",
       "2  negative  negative  \n",
       "3  positive  positive  \n",
       "4  positive  negative  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f2024-8e35-4e5a-ad91-e02423fc153b",
   "metadata": {},
   "source": [
    "##### Logistic Regression is the best model for these cleaned IMDb reviews: it gets the highest scores (accuracy 0.89, F1 0.888), is fast, and works well with TF-IDF text because a simple linear boundary fits the data and avoids overfitting. Random Forest comes second (accuracy 0.86, F1 0.862): it’s solid but heavier and harder to explain (you only get rough feature importances). Decision Tree is last (accuracy 0.70, F1 0.703): it’s easy to understand but tends to overfit sparse TF-IDF features, so it generalizes worse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
