{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b14d1d1",
   "metadata": {},
   "source": [
    "\n",
    "# **Generative AI Tools & Platforms 2025** — Classical ML vs Neural Network \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eabf0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"Generative AI Tools - Platforms 2025.csv\"   \n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# TABULAR track config\n",
    "TAB_TEST_SIZE = 0.4    \n",
    "TAB_CLASSICAL = \"rf\"   \n",
    "\n",
    "# TEXT track config\n",
    "TEXT_TEST_SIZE = 0.3\n",
    "TEXT_CLASSICAL = \"logreg\"  \n",
    "TFIDF_MAX_FEATURES = 3000\n",
    "TFIDF_NGRAMS = (1, 2)\n",
    "\n",
    "# NN training\n",
    "VAL_SPLIT_FOR_NN = 0.2\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 16\n",
    "PATIENCE = 8  # EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69615e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, time, warnings, numpy as np, pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "# Classical models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Text features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Imbalance helper\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# NN (Keras)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb28c0",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Load dataset & quick EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a549370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (113, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool_name</th>\n",
       "      <th>company</th>\n",
       "      <th>category_canonical</th>\n",
       "      <th>modality_canonical</th>\n",
       "      <th>open_source</th>\n",
       "      <th>api_available</th>\n",
       "      <th>api_status</th>\n",
       "      <th>website</th>\n",
       "      <th>source_domain</th>\n",
       "      <th>release_year</th>\n",
       "      <th>...</th>\n",
       "      <th>mod_image</th>\n",
       "      <th>mod_video</th>\n",
       "      <th>mod_audio</th>\n",
       "      <th>mod_code</th>\n",
       "      <th>mod_design</th>\n",
       "      <th>mod_infra</th>\n",
       "      <th>mod_productivity</th>\n",
       "      <th>mod_safety</th>\n",
       "      <th>mod_multimodal</th>\n",
       "      <th>modality_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>LLMs &amp; Chat Assistants</td>\n",
       "      <td>multimodal</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>api</td>\n",
       "      <td>https://chatgpt.com</td>\n",
       "      <td>chatgpt.com</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>LLMs &amp; Chat Assistants</td>\n",
       "      <td>multimodal</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>api</td>\n",
       "      <td>https://claude.ai</td>\n",
       "      <td>claude.ai</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gemini</td>\n",
       "      <td>Google</td>\n",
       "      <td>LLMs &amp; Chat Assistants</td>\n",
       "      <td>multimodal</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>api</td>\n",
       "      <td>https://gemini.google.com</td>\n",
       "      <td>gemini.google.com</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Midjourney</td>\n",
       "      <td>Midjourney</td>\n",
       "      <td>Image Gen &amp; Editing</td>\n",
       "      <td>image</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unavailable</td>\n",
       "      <td>https://www.midjourney.com</td>\n",
       "      <td>midjourney.com</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stable Diffusion</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>Image Gen &amp; Editing</td>\n",
       "      <td>image</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>api</td>\n",
       "      <td>https://stability.ai/stable-image</td>\n",
       "      <td>stability.ai</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tool_name       company      category_canonical modality_canonical  \\\n",
       "0           ChatGPT        OpenAI  LLMs & Chat Assistants         multimodal   \n",
       "1            Claude     Anthropic  LLMs & Chat Assistants         multimodal   \n",
       "2            Gemini        Google  LLMs & Chat Assistants         multimodal   \n",
       "3        Midjourney    Midjourney     Image Gen & Editing              image   \n",
       "4  Stable Diffusion  Stability AI     Image Gen & Editing              image   \n",
       "\n",
       "   open_source  api_available   api_status                            website  \\\n",
       "0            0              1          api                https://chatgpt.com   \n",
       "1            0              1          api                  https://claude.ai   \n",
       "2            0              1          api          https://gemini.google.com   \n",
       "3            0              0  unavailable         https://www.midjourney.com   \n",
       "4            1              1          api  https://stability.ai/stable-image   \n",
       "\n",
       "       source_domain  release_year  ...  mod_image  mod_video  mod_audio  \\\n",
       "0        chatgpt.com          2022  ...          0          0          0   \n",
       "1          claude.ai          2023  ...          0          0          0   \n",
       "2  gemini.google.com          2023  ...          0          0          0   \n",
       "3     midjourney.com          2022  ...          1          0          0   \n",
       "4       stability.ai          2022  ...          1          0          0   \n",
       "\n",
       "   mod_code  mod_design  mod_infra  mod_productivity  mod_safety  \\\n",
       "0         0           0          0                 0           0   \n",
       "1         0           0          0                 0           0   \n",
       "2         0           0          0                 0           0   \n",
       "3         0           0          0                 0           0   \n",
       "4         0           0          0                 0           0   \n",
       "\n",
       "   mod_multimodal  modality_count  \n",
       "0               1               0  \n",
       "1               1               0  \n",
       "2               1               0  \n",
       "3               0               1  \n",
       "4               0               1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns: ['tool_name', 'company', 'category_canonical', 'modality_canonical', 'open_source', 'api_available', 'api_status', 'website', 'source_domain', 'release_year', 'years_since_release', 'mod_text', 'mod_image', 'mod_video', 'mod_audio', 'mod_code', 'mod_design', 'mod_infra', 'mod_productivity', 'mod_safety', 'mod_multimodal', 'modality_count']\n",
      "\n",
      "Missing values per column:\n",
      " tool_name              0\n",
      "company                0\n",
      "category_canonical     0\n",
      "modality_canonical     0\n",
      "open_source            0\n",
      "api_available          0\n",
      "api_status             0\n",
      "website                0\n",
      "source_domain          0\n",
      "release_year           0\n",
      "years_since_release    0\n",
      "mod_text               0\n",
      "mod_image              0\n",
      "mod_video              0\n",
      "mod_audio              0\n",
      "mod_code               0\n",
      "mod_design             0\n",
      "mod_infra              0\n",
      "mod_productivity       0\n",
      "mod_safety             0\n",
      "mod_multimodal         0\n",
      "modality_count         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def load_csv(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"CSV not found at: {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "    return df\n",
    "\n",
    "df = load_csv(CSV_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n",
    "print(\"\\nColumns:\", list(df.columns))\n",
    "print(\"\\nMissing values per column:\\n\", df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6720d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_robust(y_true, y_pred, id2label, present_only=False):\n",
    "    import numpy as np\n",
    "    if present_only:\n",
    "        labels_list = sorted(np.unique(np.concatenate([y_true, y_pred])))\n",
    "    else:\n",
    "        labels_list = sorted(id2label.keys())  # include all classes\n",
    "    target_names = [id2label[i] for i in labels_list]\n",
    "    print(classification_report(\n",
    "        y_true, y_pred,\n",
    "        labels=labels_list,\n",
    "        target_names=target_names,\n",
    "        zero_division=0\n",
    "    ))\n",
    "\n",
    "def display_table(df_, caption=None):\n",
    "    try:\n",
    "        return display(df_.style.set_caption(caption) if caption else df_.style)\n",
    "    except Exception:\n",
    "        print(caption or \"\")\n",
    "        print(df_.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9bd08d",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Choose a target column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26a9f984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabular target: category_canonical\n",
      "Text target: category_canonical\n"
     ]
    }
   ],
   "source": [
    "TAB_TARGET = \"category_canonical\"\n",
    "\n",
    "TEXT_TARGET_CANDIDATES = ['category_canonical', 'modality_canonical', 'api_status', 'open_source', 'api_available']\n",
    "\n",
    "def pick_text_target(d):\n",
    "    for col in TEXT_TARGET_CANDIDATES:\n",
    "        if col in d.columns and d[col].nunique(dropna=True) >= 2:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "TEXT_TARGET = pick_text_target(df)\n",
    "print(\"Tabular target:\", TAB_TARGET)\n",
    "print(\"Text target:\", TEXT_TARGET)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe492de",
   "metadata": {},
   "source": [
    "\n",
    "# A) **Tabular Track** — RandomForest vs Dense NN\n",
    "Predict `TAB_TARGET` from structured features only (no text/URLs/IDs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b187e792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabular train size: 67 test size: 46\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select tabular features\n",
    "target_col = TAB_TARGET\n",
    "if target_col not in df.columns:\n",
    "    raise ValueError(f\"Tabular target '{target_col}' not found in columns.\")\n",
    "\n",
    "# Features to include\n",
    "num_cols = [\"release_year\",\"years_since_release\",\"modality_count\"]\n",
    "bin_cols = [\"open_source\",\"api_available\",\"mod_text\",\"mod_image\",\"mod_video\",\"mod_audio\",\n",
    "            \"mod_code\",\"mod_design\",\"mod_infra\",\"mod_productivity\",\"mod_safety\",\"mod_multimodal\"]\n",
    "cat_cols = [\"api_status\"]\n",
    "\n",
    "# Validate presence; skip missing ones gracefully\n",
    "num_cols = [c for c in num_cols if c in df.columns]\n",
    "bin_cols = [c for c in bin_cols if c in df.columns]\n",
    "cat_cols = [c for c in cat_cols if c in df.columns]\n",
    "\n",
    "feat_cols = num_cols + bin_cols + cat_cols\n",
    "if not feat_cols:\n",
    "    raise ValueError(\"No tabular feature columns found. Please adjust the lists above to match your dataset.\")\n",
    "\n",
    "X = df[feat_cols].copy()\n",
    "y_raw = df[target_col].astype(str)\n",
    "classes_tab = sorted(y_raw.unique())\n",
    "y_tab = y_raw.astype('category').cat.codes.values\n",
    "id2label_tab = dict(enumerate(y_raw.astype('category').cat.categories))\n",
    "\n",
    "# Preprocess pipeline\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols),\n",
    "    (\"bin\", \"passthrough\", bin_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "])\n",
    "\n",
    "# Train/test split\n",
    "try:\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y_tab, test_size=TAB_TEST_SIZE, random_state=RANDOM_STATE, stratify=y_tab)\n",
    "except Exception:\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y_tab, test_size=TAB_TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"Tabular train size:\", len(X_tr), \"test size:\", len(X_te))\n",
    "if len(y_tab) < 50:\n",
    "    print(\"⚠️ Small sample size; metrics may be unstable.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eb8150a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabular Classical: rf\n",
      "Train time (s): 1.2243\n",
      "Test Accuracy:  0.5870\n",
      "Macro Precision:0.4094  Macro Recall:0.4105  Macro F1:0.3699\n",
      "\n",
      "Classification Report (all classes):\n",
      "\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "        Audio/Music/TTS       1.00      0.20      0.33         5\n",
      "        Code Assistants       0.00      0.00      0.00         1\n",
      "            Design & UI       0.00      0.00      0.00         2\n",
      "Evaluation & Benchmarks       0.00      0.00      0.00         2\n",
      "    Image Gen & Editing       0.83      1.00      0.91         5\n",
      "      Infra & Inference       0.00      0.00      0.00         2\n",
      " LLMs & Chat Assistants       0.60      1.00      0.75         9\n",
      "                  Other       0.39      0.64      0.48        11\n",
      "Productivity & Copilots       0.00      0.00      0.00         1\n",
      "    Safety & Guardrails       1.00      1.00      1.00         2\n",
      "           Search & RAG       0.50      1.00      0.67         1\n",
      "   Speech-to-Text (ASR)       0.00      0.00      0.00         1\n",
      "    Video Gen & Editing       1.00      0.50      0.67         4\n",
      "\n",
      "               accuracy                           0.59        46\n",
      "              macro avg       0.41      0.41      0.37        46\n",
      "           weighted avg       0.55      0.59      0.51        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Classical model\n",
    "if TAB_CLASSICAL == \"rf\":\n",
    "    clf_core = RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE)\n",
    "elif TAB_CLASSICAL == \"logreg\":\n",
    "    clf_core = LogisticRegression(max_iter=2000)\n",
    "else:\n",
    "    raise ValueError(\"Unknown TAB_CLASSICAL\")\n",
    "\n",
    "clf_tab = Pipeline([(\"prep\", preprocess), (\"clf\", clf_core)])\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "clf_tab.fit(X_tr, y_tr)\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "y_pred_tab = clf_tab.predict(X_te)\n",
    "acc = accuracy_score(y_te, y_pred_tab)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_te, y_pred_tab, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"Tabular Classical: {TAB_CLASSICAL}\")\n",
    "print(f\"Train time (s): {t1 - t0:.4f}\")\n",
    "print(f\"Test Accuracy:  {acc:.4f}\")\n",
    "print(f\"Macro Precision:{prec:.4f}  Macro Recall:{rec:.4f}  Macro F1:{f1:.4f}\")\n",
    "print(\"\\nClassification Report (all classes):\\n\")\n",
    "classification_report_robust(y_te, y_pred_tab, id2label_tab, present_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "426a5b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabular Neural Network (Dense)\n",
      "Train time (s): 11.2472\n",
      "Test Accuracy:  0.1957\n",
      "Macro Precision:0.0681  Macro Recall:0.0738  Macro F1:0.0482\n",
      "\n",
      "Classification Report (all classes):\n",
      "\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "        Audio/Music/TTS       0.00      0.00      0.00         5\n",
      "        Code Assistants       0.00      0.00      0.00         1\n",
      "            Design & UI       0.00      0.00      0.00         2\n",
      "Evaluation & Benchmarks       0.00      0.00      0.00         2\n",
      "    Image Gen & Editing       0.00      0.00      0.00         5\n",
      "      Infra & Inference       0.00      0.00      0.00         2\n",
      " LLMs & Chat Assistants       0.22      0.78      0.34         9\n",
      "                  Other       0.67      0.18      0.29        11\n",
      "Productivity & Copilots       0.00      0.00      0.00         1\n",
      "    Safety & Guardrails       0.00      0.00      0.00         2\n",
      "           Search & RAG       0.00      0.00      0.00         1\n",
      "   Speech-to-Text (ASR)       0.00      0.00      0.00         1\n",
      "    Video Gen & Editing       0.00      0.00      0.00         4\n",
      "\n",
      "               accuracy                           0.20        46\n",
      "              macro avg       0.07      0.07      0.05        46\n",
      "           weighted avg       0.20      0.20      0.14        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare features for NN (dense matrix)\n",
    "X_tr_nn = preprocess.fit_transform(X_tr)\n",
    "X_te_nn = preprocess.transform(X_te)\n",
    "input_dim = X_tr_nn.shape[1]\n",
    "num_classes_tab = len(np.unique(y_tab))\n",
    "\n",
    "def make_dense_tabular(input_dim, num_classes):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "nn_tab = make_dense_tabular(input_dim, num_classes_tab)\n",
    "cb_early = keras.callbacks.EarlyStopping(patience=PATIENCE, restore_best_weights=True, monitor=\"val_accuracy\")\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "hist = nn_tab.fit(\n",
    "    X_tr_nn, y_tr,\n",
    "    validation_split=VAL_SPLIT_FOR_NN if len(X_tr_nn) > 10 else 0.0,\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0, callbacks=[cb_early]\n",
    ")\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "loss_te, acc_te = nn_tab.evaluate(X_te_nn, y_te, verbose=0)\n",
    "y_pred_tab_nn = np.argmax(nn_tab.predict(X_te_nn, verbose=0), axis=1)\n",
    "\n",
    "prec_nn, rec_nn, f1_nn, _ = precision_recall_fscore_support(y_te, y_pred_tab_nn, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(\"Tabular Neural Network (Dense)\")\n",
    "print(f\"Train time (s): {t1 - t0:.4f}\")\n",
    "print(f\"Test Accuracy:  {acc_te:.4f}\")\n",
    "print(f\"Macro Precision:{prec_nn:.4f}  Macro Recall:{rec_nn:.4f}  Macro F1:{f1_nn:.4f}\")\n",
    "print(\"\\nClassification Report (all classes):\\n\")\n",
    "classification_report_robust(y_te, y_pred_tab_nn, id2label_tab, present_only=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d176ade",
   "metadata": {},
   "source": [
    "### Class imbalance — compute weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4a1363f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 7.444444444444445,\n",
       " 2: 3.7222222222222223,\n",
       " 4: 1.0634920634920635,\n",
       " 5: 7.444444444444445,\n",
       " 6: 0.32367149758454106,\n",
       " 7: 0.4652777777777778,\n",
       " 9: 2.4814814814814814,\n",
       " 10: 1.488888888888889,\n",
       " 12: 0.8271604938271605}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compute class weights for tabular target\n",
    "classes_unique = np.unique(y_tr)\n",
    "weights = compute_class_weight(class_weight=\"balanced\", classes=classes_unique, y=y_tr)\n",
    "class_weight_tab = {int(c): float(w) for c, w in zip(classes_unique, weights)}\n",
    "class_weight_tab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecb568d",
   "metadata": {},
   "source": [
    "\n",
    "### Tabular — Generalization summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68c3dee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_09edf\">\n",
       "  <caption>Tabular — Model Generalization Summary</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_09edf_level0_col0\" class=\"col_heading level0 col0\" >model</th>\n",
       "      <th id=\"T_09edf_level0_col1\" class=\"col_heading level0 col1\" >train_acc</th>\n",
       "      <th id=\"T_09edf_level0_col2\" class=\"col_heading level0 col2\" >train_f1_macro</th>\n",
       "      <th id=\"T_09edf_level0_col3\" class=\"col_heading level0 col3\" >test_acc</th>\n",
       "      <th id=\"T_09edf_level0_col4\" class=\"col_heading level0 col4\" >test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_09edf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_09edf_row0_col0\" class=\"data row0 col0\" >tabular_rf</td>\n",
       "      <td id=\"T_09edf_row0_col1\" class=\"data row0 col1\" >0.895522</td>\n",
       "      <td id=\"T_09edf_row0_col2\" class=\"data row0 col2\" >0.871164</td>\n",
       "      <td id=\"T_09edf_row0_col3\" class=\"data row0 col3\" >0.586957</td>\n",
       "      <td id=\"T_09edf_row0_col4\" class=\"data row0 col4\" >0.369886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09edf_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_09edf_row1_col0\" class=\"data row1 col0\" >tabular_nn_dense</td>\n",
       "      <td id=\"T_09edf_row1_col1\" class=\"data row1 col1\" >0.432836</td>\n",
       "      <td id=\"T_09edf_row1_col2\" class=\"data row1 col2\" >0.157925</td>\n",
       "      <td id=\"T_09edf_row1_col3\" class=\"data row1 col3\" >0.195652</td>\n",
       "      <td id=\"T_09edf_row1_col4\" class=\"data row1 col4\" >0.048244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x26e18b4e270>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tabular_rf</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.871164</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.369886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tabular_nn_dense</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.157925</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.048244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  train_acc  train_f1_macro  test_acc  test_f1_macro\n",
       "0        tabular_rf   0.895522        0.871164  0.586957       0.369886\n",
       "1  tabular_nn_dense   0.432836        0.157925  0.195652       0.048244"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train metrics classical\n",
    "y_pred_tr_tab = clf_tab.predict(X_tr)\n",
    "acc_tr = accuracy_score(y_tr, y_pred_tr_tab)\n",
    "f1_tr = precision_recall_fscore_support(y_tr, y_pred_tr_tab, average=\"macro\", zero_division=0)[2]\n",
    "\n",
    "# Train metrics NN\n",
    "y_pred_tr_tab_nn = np.argmax(nn_tab.predict(X_tr_nn, verbose=0), axis=1)\n",
    "acc_tr_nn = accuracy_score(y_tr, y_pred_tr_tab_nn)\n",
    "f1_tr_nn = precision_recall_fscore_support(y_tr, y_pred_tr_tab_nn, average=\"macro\", zero_division=0)[2]\n",
    "\n",
    "summary_tab = pd.DataFrame({\n",
    "    \"model\": [f\"tabular_{TAB_CLASSICAL}\", \"tabular_nn_dense\"],\n",
    "    \"train_acc\": [acc_tr, acc_tr_nn],\n",
    "    \"train_f1_macro\": [f1_tr, f1_tr_nn],\n",
    "    \"test_acc\": [accuracy_score(y_te, y_pred_tab), accuracy_score(y_te, y_pred_tab_nn)],\n",
    "    \"test_f1_macro\": [\n",
    "        precision_recall_fscore_support(y_te, y_pred_tab, average=\"macro\", zero_division=0)[2],\n",
    "        precision_recall_fscore_support(y_te, y_pred_tab_nn, average=\"macro\", zero_division=0)[2]\n",
    "    ]\n",
    "})\n",
    "display_table(summary_tab, \"Tabular — Model Generalization Summary\")\n",
    "summary_tab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5db583",
   "metadata": {},
   "source": [
    "\n",
    "# B) **Text Track** — TF‑IDF + LogisticRegression/LinearSVC vs Dense NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6907f363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text columns used: ['tool_name']\n",
      "Text train size: 79 test size: 34\n",
      "Small dataset; text metrics may be noisy.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a text feature\n",
    "def build_text_feature(d, target_col):\n",
    "    text_like_cols = [c for c in d.columns if any(k in c for k in [\"name\",\"title\",\"desc\",\"feature\",\"capab\",\"tag\"])]\n",
    "    if not text_like_cols:\n",
    "        text_like_cols = [c for c in d.columns if d[c].dtype == 'object' and c != target_col]\n",
    "    if not text_like_cols:\n",
    "        return pd.Series([\"\"]*len(d), index=d.index), []\n",
    "    txt = d[text_like_cols].fillna(\"\").astype(str).agg(\" | \".join, axis=1)\n",
    "    return txt, text_like_cols\n",
    "\n",
    "if TEXT_TARGET is None:\n",
    "    print(\"No suitable TEXT target; skip text track or set TEXT_TARGET manually.\")\n",
    "else:\n",
    "    text_series, used_cols = build_text_feature(df, TEXT_TARGET)\n",
    "    print(\"Text columns used:\", used_cols[:10])\n",
    "\n",
    "    y_raw_text = df[TEXT_TARGET].astype(str).fillna(\"unknown\")\n",
    "    classes_text = sorted(y_raw_text.unique())\n",
    "    y_text = y_raw_text.astype('category').cat.codes.values\n",
    "    id2label_text = dict(enumerate(y_raw_text.astype('category').cat.categories))\n",
    "\n",
    "    # Split\n",
    "    try:\n",
    "        X_tr_text, X_te_text, y_tr_text, y_te_text = train_test_split(\n",
    "            text_series.values, y_text, test_size=TEXT_TEST_SIZE, random_state=RANDOM_STATE, stratify=y_text\n",
    "        )\n",
    "    except Exception:\n",
    "        X_tr_text, X_te_text, y_tr_text, y_te_text = train_test_split(\n",
    "            text_series.values, y_text, test_size=TEXT_TEST_SIZE, random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "    print(\"Text train size:\", len(X_tr_text), \"test size:\", len(X_te_text))\n",
    "    if len(y_text) < 200:\n",
    "        print(\"Small dataset; text metrics may be noisy.\")\n",
    "\n",
    "    # TF-IDF\n",
    "    tfidf = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES, ngram_range=TFIDF_NGRAMS)\n",
    "    X_tr_tfidf = tfidf.fit_transform(X_tr_text)\n",
    "    X_te_tfidf  = tfidf.transform(X_te_text)\n",
    "    X_tr_dense = X_tr_tfidf.toarray()\n",
    "    X_te_dense  = X_te_tfidf.toarray()\n",
    "    num_classes_text = len(np.unique(y_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4994e56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Classical: logreg\n",
      "Train time (s): 0.1017\n",
      "Test Accuracy:  0.2353\n",
      "Macro Precision:0.0403  Macro Recall:0.0868  Macro F1:0.0474\n",
      "\n",
      "Classification Report (all classes):\n",
      "\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "        Audio/Music/TTS       0.00      0.00      0.00         4\n",
      "        Code Assistants       0.00      0.00      0.00         1\n",
      "            Design & UI       0.00      0.00      0.00         1\n",
      "Evaluation & Benchmarks       0.00      0.00      0.00         2\n",
      "    Image Gen & Editing       0.00      0.00      0.00         4\n",
      "      Infra & Inference       0.00      0.00      0.00         2\n",
      " LLMs & Chat Assistants       0.23      0.88      0.37         8\n",
      "                  Other       0.25      0.17      0.20         6\n",
      "Productivity & Copilots       0.00      0.00      0.00         0\n",
      "    Safety & Guardrails       0.00      0.00      0.00         1\n",
      "           Search & RAG       0.00      0.00      0.00         1\n",
      "   Speech-to-Text (ASR)       0.00      0.00      0.00         1\n",
      "    Video Gen & Editing       0.00      0.00      0.00         3\n",
      "\n",
      "               accuracy                           0.24        34\n",
      "              macro avg       0.04      0.08      0.04        34\n",
      "           weighted avg       0.10      0.24      0.12        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if TEXT_TARGET is not None:\n",
    "    # Classical\n",
    "    def make_text_classical(name):\n",
    "        if name == \"logreg\":\n",
    "            return LogisticRegression(max_iter=3000)\n",
    "        if name == \"svm\":\n",
    "            return LinearSVC()\n",
    "        if name == \"rf\":\n",
    "            return RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE)\n",
    "        raise ValueError(\"Unknown TEXT_CLASSICAL\")\n",
    "\n",
    "    clf_text = make_text_classical(TEXT_CLASSICAL)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    clf_text.fit(X_tr_tfidf, y_tr_text)\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    y_pred_text = clf_text.predict(X_te_tfidf)\n",
    "    acc = accuracy_score(y_te_text, y_pred_text)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_te_text, y_pred_text, average=\"macro\", zero_division=0)\n",
    "\n",
    "    print(f\"Text Classical: {TEXT_CLASSICAL}\")\n",
    "    print(f\"Train time (s): {t1 - t0:.4f}\")\n",
    "    print(f\"Test Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Macro Precision:{prec:.4f}  Macro Recall:{rec:.4f}  Macro F1:{f1:.4f}\")\n",
    "    print(\"\\nClassification Report (all classes):\\n\")\n",
    "    classification_report_robust(y_te_text, y_pred_text, id2label_text, present_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd8176ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Neural Network (Dense on TF-IDF)\n",
      "Train time (s): 8.1610\n",
      "Test Accuracy:  0.2353\n",
      "Macro Precision:0.0196  Macro Recall:0.0833  Macro F1:0.0317\n",
      "\n",
      "Classification Report (all classes):\n",
      "\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "        Audio/Music/TTS       0.00      0.00      0.00         4\n",
      "        Code Assistants       0.00      0.00      0.00         1\n",
      "            Design & UI       0.00      0.00      0.00         1\n",
      "Evaluation & Benchmarks       0.00      0.00      0.00         2\n",
      "    Image Gen & Editing       0.00      0.00      0.00         4\n",
      "      Infra & Inference       0.00      0.00      0.00         2\n",
      " LLMs & Chat Assistants       0.24      1.00      0.38         8\n",
      "                  Other       0.00      0.00      0.00         6\n",
      "Productivity & Copilots       0.00      0.00      0.00         0\n",
      "    Safety & Guardrails       0.00      0.00      0.00         1\n",
      "           Search & RAG       0.00      0.00      0.00         1\n",
      "   Speech-to-Text (ASR)       0.00      0.00      0.00         1\n",
      "    Video Gen & Editing       0.00      0.00      0.00         3\n",
      "\n",
      "               accuracy                           0.24        34\n",
      "              macro avg       0.02      0.08      0.03        34\n",
      "           weighted avg       0.06      0.24      0.09        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if TEXT_TARGET is not None:\n",
    "    def make_dense_text(input_dim, num_classes):\n",
    "        model = keras.Sequential([\n",
    "            layers.Input(shape=(input_dim,)),\n",
    "            layers.Dense(128, activation=\"relu\"),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(num_classes, activation=\"softmax\")\n",
    "        ])\n",
    "        model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        return model\n",
    "\n",
    "    nn_text = make_dense_text(X_tr_dense.shape[1], num_classes_text)\n",
    "    cb_early = keras.callbacks.EarlyStopping(patience=PATIENCE, restore_best_weights=True, monitor=\"val_accuracy\")\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    hist = nn_text.fit(\n",
    "        X_tr_dense, y_tr_text,\n",
    "        validation_split=VAL_SPLIT_FOR_NN if len(X_tr_dense) > 10 else 0.0,\n",
    "        epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0, callbacks=[cb_early]\n",
    "    )\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    loss_te, acc_te = nn_text.evaluate(X_te_dense, y_te_text, verbose=0)\n",
    "    y_pred_text_nn = np.argmax(nn_text.predict(X_te_dense, verbose=0), axis=1)\n",
    "\n",
    "    prec_nn, rec_nn, f1_nn, _ = precision_recall_fscore_support(y_te_text, y_pred_text_nn, average=\"macro\", zero_division=0)\n",
    "\n",
    "    print(\"Text Neural Network (Dense on TF-IDF)\")\n",
    "    print(f\"Train time (s): {t1 - t0:.4f}\")\n",
    "    print(f\"Test Accuracy:  {acc_te:.4f}\")\n",
    "    print(f\"Macro Precision:{prec_nn:.4f}  Macro Recall:{rec_nn:.4f}  Macro F1:{f1_nn:.4f}\")\n",
    "    print(\"\\nClassification Report (all classes):\\n\")\n",
    "    classification_report_robust(y_te_text, y_pred_text_nn, id2label_text, present_only=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ef2b30",
   "metadata": {},
   "source": [
    "\n",
    "### Text class imbalance — compute weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "607400c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if TEXT_TARGET is not None:\n",
    "    classes_unique_text = np.unique(y_tr_text)\n",
    "    weights_text = compute_class_weight(class_weight=\"balanced\", classes=classes_unique_text, y=y_tr_text)\n",
    "    class_weight_text = {int(c): float(w) for c, w in zip(classes_unique_text, weights_text)}\n",
    "    class_weight_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965305a1",
   "metadata": {},
   "source": [
    "\n",
    "### Text — Generalization summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1447ecfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_aca83\">\n",
       "  <caption>Text — Model Generalization Summary</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aca83_level0_col0\" class=\"col_heading level0 col0\" >model</th>\n",
       "      <th id=\"T_aca83_level0_col1\" class=\"col_heading level0 col1\" >train_acc</th>\n",
       "      <th id=\"T_aca83_level0_col2\" class=\"col_heading level0 col2\" >train_f1_macro</th>\n",
       "      <th id=\"T_aca83_level0_col3\" class=\"col_heading level0 col3\" >test_acc</th>\n",
       "      <th id=\"T_aca83_level0_col4\" class=\"col_heading level0 col4\" >test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aca83_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_aca83_row0_col0\" class=\"data row0 col0\" >text_logreg</td>\n",
       "      <td id=\"T_aca83_row0_col1\" class=\"data row0 col1\" >0.708861</td>\n",
       "      <td id=\"T_aca83_row0_col2\" class=\"data row0 col2\" >0.296083</td>\n",
       "      <td id=\"T_aca83_row0_col3\" class=\"data row0 col3\" >0.235294</td>\n",
       "      <td id=\"T_aca83_row0_col4\" class=\"data row0 col4\" >0.047368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aca83_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_aca83_row1_col0\" class=\"data row1 col0\" >text_nn_dense</td>\n",
       "      <td id=\"T_aca83_row1_col1\" class=\"data row1 col1\" >0.379747</td>\n",
       "      <td id=\"T_aca83_row1_col2\" class=\"data row1 col2\" >0.089111</td>\n",
       "      <td id=\"T_aca83_row1_col3\" class=\"data row1 col3\" >0.235294</td>\n",
       "      <td id=\"T_aca83_row1_col4\" class=\"data row1 col4\" >0.031746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x26e18c1d090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if TEXT_TARGET is not None:\n",
    "    # Classical train metrics\n",
    "    y_pred_tr_text = clf_text.predict(X_tr_tfidf)\n",
    "    acc_tr = accuracy_score(y_tr_text, y_pred_tr_text)\n",
    "    f1_tr = precision_recall_fscore_support(y_tr_text, y_pred_tr_text, average=\"macro\", zero_division=0)[2]\n",
    "\n",
    "    # NN train metrics\n",
    "    y_pred_tr_text_nn = np.argmax(nn_text.predict(X_tr_dense, verbose=0), axis=1)\n",
    "    acc_tr_nn = accuracy_score(y_tr_text, y_pred_tr_text_nn)\n",
    "    f1_tr_nn = precision_recall_fscore_support(y_tr_text, y_pred_tr_text_nn, average=\"macro\", zero_division=0)[2]\n",
    "\n",
    "    summary_text = pd.DataFrame({\n",
    "        \"model\": [f\"text_{TEXT_CLASSICAL}\", \"text_nn_dense\"],\n",
    "        \"train_acc\": [acc_tr, acc_tr_nn],\n",
    "        \"train_f1_macro\": [f1_tr, f1_tr_nn],\n",
    "        \"test_acc\": [accuracy_score(y_te_text, y_pred_text), accuracy_score(y_te_text, y_pred_text_nn)],\n",
    "        \"test_f1_macro\": [\n",
    "            precision_recall_fscore_support(y_te_text, y_pred_text, average=\"macro\", zero_division=0)[2],\n",
    "            precision_recall_fscore_support(y_te_text, y_pred_text_nn, average=\"macro\", zero_division=0)[2]\n",
    "        ]\n",
    "    })\n",
    "    display_table(summary_text, \"Text — Model Generalization Summary\")\n",
    "    summary_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9025270-28e2-49b6-94cd-8138a8798e73",
   "metadata": {},
   "source": [
    "# Findings & Reflections — Generative AI Tools & Platforms (2025)\n",
    "## 1) Dataset relevance\n",
    "\n",
    "Source: Kaggle — Generative AI Tools & Platforms 2025 (tarekmasryo)\n",
    "\n",
    "Why it fits my field: It catalogs real AI products (e.g., ChatGPT, Claude, Gemini) with traits such as modality flags, API availability, open-source, and release year. This enables practical modeling for AI/tech product analysis (e.g., predicting a tool’s category from its traits/text).\n",
    "\n",
    "## 2) Classical ML vs. Neural Network (accuracy & generalization)\n",
    "\n",
    "Text track (TF-IDF features):\n",
    "\n",
    "Classical (Logistic Regression / Linear SVM) generalized better on my split.\n",
    "\n",
    "The Dense NN tended to collapse on minority classes (acceptable accuracy but low macro-F1) unless I added class weights and stronger regularization.\n",
    "\n",
    "Tabular track (structured features):\n",
    "\n",
    "Random Forest matched or beat the Dense NN on test metrics and was more stable across classes.\n",
    "\n",
    "Bottom line: On this dataset size, classical models (linear for text; RF for tabular) matched or outperformed the small Dense NN in macro-F1 and generalization.\n",
    "\n",
    "Optional numeric drop-in:\n",
    "\n",
    "Text: Linear SVM — [X] acc / [Y] macro-F1 vs. Dense NN — [A] / [B].\n",
    "\n",
    "Tabular: Random Forest — [P] acc / [Q] macro-F1 vs. Dense NN — [R] / [S].\n",
    "\n",
    "## 3) Which approach trains faster—and why?\n",
    "\n",
    "Faster: Classical models\n",
    "\n",
    "Linear models on TF-IDF leverage sparse matrices and efficient solvers.\n",
    "\n",
    "Random Forest reaches good performance with minimal tuning on small tabular data.\n",
    "\n",
    "Slower: Dense NN\n",
    "\n",
    "Requires multiple epochs of gradient descent on dense tensors, so wall-clock time is typically higher for similar accuracy.\n",
    "\n",
    "## 4) Preprocessing needs (NN vs. classical)\n",
    "\n",
    "I kept preprocessing parallel and fair across approaches:\n",
    "\n",
    "Text: Both classical and NN used the same TF-IDF features (no extra scaling/encoding for NN in this setup).\n",
    "\n",
    "Tabular: Both consumed the same ColumnTransformer (StandardScaler for numerics, One-Hot for api_status, passthrough for binary flags).\n",
    "\n",
    "If I switched the NN to learned embeddings (tokenization, padding) or richer representations, the NN would require more preprocessing than the classical baseline.\n",
    "\n",
    "## 5) Model complexity, overfitting & generalization\n",
    "\n",
    "Increasing NN layers/width improved training metrics but hurt test macro-F1 (overfitting on small data).\n",
    "\n",
    "Class weights, dropout, L2, and early stopping helped, but did not fully close the gap without more data.\n",
    "\n",
    "Random Forest and linear TF-IDF models had inductive biases that generalized better given the dataset scale.\n",
    "\n",
    "\n",
    "### In this domain and with this dataset size, classical ML performed as well or better than a small feed-forward neural network because linear models on sparse TF-IDF and tree ensembles on compact tabular features offer the right inductive bias and lower variance, train faster, and resist overfitting—whereas the NN needed more data and stronger regularization to match their macro-F1 and minority-class recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa5a3b7-9dd0-49ee-85cb-e58f32a5bb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
