{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f243cde",
   "metadata": {},
   "source": [
    "# IMDb Sentiment Classification — Logistic Regression vs Decision Tree vs Random Forest\n",
    "**Generated:** 2025-09-12 12:49:21\n",
    "\n",
    "This notebook uses a **cleaned IMDb reviews dataset** (with columns `cleaned_review` and `label`) to:\n",
    "- Vectorize text with **TF‑IDF**\n",
    "- Train **Logistic Regression**, **Decision Tree**, and **Random Forest**\n",
    "- Evaluate with **Accuracy, Precision, Recall, F1-score**\n",
    "- Compare performance in a single table\n",
    "- Show **example predictions** and discuss **interpretability vs performance**\n",
    "\n",
    "> **Expected input file**: a CSV with columns:\n",
    "> - `cleaned_review` (string, preprocessed text)\n",
    "> - `label` (string, `positive` or `negative`)\n",
    "\n",
    "If your file is elsewhere or has a different name, change `DATA_PATH` below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1832fea",
   "metadata": {},
   "source": [
    "## 1) Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7c7527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0335c4",
   "metadata": {},
   "source": [
    "## 2) Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f9422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 rows (dropped 0 with missing values).\n",
      "\n",
      "sentiment distribution:\n",
      "sentiment\n",
      "positive    25000\n",
      "negative    25000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>bromwell high cartoon comedy ran time program ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>homelessness houselessness george carlin state...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>brilliant acting lesley ann warren best dramat...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>easily underrated film inn brook cannon sure f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>typical mel brook film much less slapstick mov...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...   \n",
       "1  Homelessness (or Houselessness as George Carli...   \n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...   \n",
       "3  This is easily the most underrated film inn th...   \n",
       "4  This is not the typical Mel Brooks film. It wa...   \n",
       "\n",
       "                                      cleaned_review sentiment  \n",
       "0  bromwell high cartoon comedy ran time program ...  positive  \n",
       "1  homelessness houselessness george carlin state...  positive  \n",
       "2  brilliant acting lesley ann warren best dramat...  positive  \n",
       "3  easily underrated film inn brook cannon sure f...  positive  \n",
       "4  typical mel brook film much less slapstick mov...  positive  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"imdb_acl_cleaned.csv\" \n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Basic validation\n",
    "expected_cols = {'cleaned_review', 'sentiment'}\n",
    "missing = expected_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Dataset is missing required columns: {missing}\")\n",
    "\n",
    "before = len(df)\n",
    "df = df.dropna(subset=['cleaned_review', 'sentiment']).copy()\n",
    "after = len(df)\n",
    "\n",
    "print(f'Loaded {after} rows (dropped {before - after} with missing values).')\n",
    "print(\"\\nsentiment distribution:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b119cf",
   "metadata": {},
   "source": [
    "## 3) Train/Test Split (80/20, stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "face524e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 40000, Test size: 10000\n"
     ]
    }
   ],
   "source": [
    "X_text = df['cleaned_review'].astype(str)\n",
    "y = df['sentiment'].astype(str)\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train_text)}, Test size: {len(X_test_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50456aaa",
   "metadata": {},
   "source": [
    "## 4) TF‑IDF Vectorization (fit on train, transform train & test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e2c784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shapes -> Train: (40000, 81344), Test: (10000, 81344)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X_train = tfidf.fit_transform(X_train_text)\n",
    "X_test = tfidf.transform(X_test_text)\n",
    "\n",
    "print(f\"TF-IDF matrix shapes -> Train: {X_train.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360f7650",
   "metadata": {},
   "source": [
    "## 5) Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de302017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression...\n",
      "Training DecisionTree...\n",
      "Training RandomForest...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=RANDOM_STATE, n_jobs=None),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "}\n",
    "\n",
    "fitted = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    fitted[name] = model\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4292083d",
   "metadata": {},
   "source": [
    "## 6) Evaluation — Accuracy, Precision, Recall, F1 & Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c70d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_te, y_te):\n",
    "    preds = model.predict(X_te)\n",
    "    acc = accuracy_score(y_te, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_te, preds, average='weighted', zero_division=0)\n",
    "    report = classification_report(y_te, preds, digits=3, zero_division=0)\n",
    "    cm = confusion_matrix(y_te, preds, labels=sorted(y_te.unique()))\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"report\": report,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"sentiment\": sorted(y_te.unique())\n",
    "    }\n",
    "\n",
    "results = []\n",
    "for name, model in fitted.items():\n",
    "    res = evaluate_model(name, model, X_test, y_test)\n",
    "    results.append(res)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(res['report'])\n",
    "    print(\"Confusion Matrix (rows=true, cols=pred):\")\n",
    "    print(pd.DataFrame(res['confusion_matrix'], index=res['sentiment'], columns=res['labels']))\n",
    "\n",
    "# Comparison table\n",
    "metrics_table = pd.DataFrame([\n",
    "    {\"Model\": r[\"name\"], \"Accuracy\": r[\"accuracy\"], \"Precision(w)\": r[\"precision\"], \"Recall(w)\": r[\"recall\"], \"F1(w)\": r[\"f1\"]}\n",
    "    for r in results\n",
    "]).sort_values(by=\"F1(w)\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "metrics_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb1eceb",
   "metadata": {},
   "source": [
    "### (Optional) F1-score Comparison Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b1a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single chart with matplotlib only (no styles/colors set)\n",
    "plt.figure()\n",
    "plt.bar(metrics_table['Model'], metrics_table['F1(w)'])\n",
    "plt.title('F1-score (weighted) by Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('F1-score (weighted)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae077a46",
   "metadata": {},
   "source": [
    "## 7) Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a few example predictions for each model\n",
    "N = 10  # number of examples\n",
    "sample_idx = np.random.choice(len(X_test_text), size=min(N, len(X_test_text)), replace=False)\n",
    "examples = pd.DataFrame({\n",
    "    \"cleaned_review\": X_test_text.iloc[sample_idx].values,\n",
    "    \"true_label\": y_test.iloc[sample_idx].values\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "for name, model in fitted.items():\n",
    "    preds = model.predict(tfidf.transform(examples['cleaned_review']))\n",
    "    examples[name + \"_pred\"] = preds\n",
    "\n",
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ffaa0d",
   "metadata": {},
   "source": [
    "## 8) Insights — Which model works best and why?\n",
    "- **Logistic Regression** often performs best on TF‑IDF text features because it's a linear model that handles **high-dimensional sparse vectors** well and tends to generalize nicely.\n",
    "- **Decision Trees** can overfit sparse high‑dimensional text very easily, typically leading to lower generalization performance.\n",
    "- **Random Forest** reduces overfitting vs. a single tree and can perform competitively, but with TF‑IDF text features, linear models frequently edge it out. Forests are also more computationally expensive.\n",
    "\n",
    "**Interpretability vs Performance:**\n",
    "- **Decision Tree** is the most interpretable (you can visualize rules), but may underperform.\n",
    "- **Logistic Regression** is fairly interpretable (inspect top coefficients per class) and tends to be strongest on sparse TF‑IDF features.\n",
    "- **Random Forest** is less interpretable than a single tree but sometimes improves robustness at the cost of transparency.\n",
    "\n",
    "> Tip: If you need even better performance, consider tuning hyperparameters (e.g., `ngram_range`, `min_df`, regularization strength, tree depth), or try linear SVMs, calibrated Naive Bayes, or modern transformer models (e.g., fine‑tuning a small BERT)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515e925b",
   "metadata": {},
   "source": [
    "### (Optional) Inspect Top Words for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87cce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section provides a quick peek at top weighted features per class for interpretability.\n",
    "# It will only run if the model is LogisticRegression.\n",
    "if 'LogisticRegression' in fitted and hasattr(fitted['LogisticRegression'], 'coef_'):\n",
    "    lr = fitted['LogisticRegression']\n",
    "    feature_names = np.array(tfidf.get_feature_names_out())\n",
    "    classes = lr.classes_\n",
    "    top_k = 20\n",
    "    for i, cls in enumerate(classes):\n",
    "        coefs = lr.coef_[i]\n",
    "        top_pos_idx = np.argsort(coefs)[-top_k:][::-1]\n",
    "        print(f\"\\nTop {top_k} words pushing towards class='{cls}':\")\n",
    "        for w, c in zip(feature_names[top_pos_idx], coefs[top_pos_idx]):\n",
    "            print(f\"{w:>20s}  {c: .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27125868",
   "metadata": {},
   "source": [
    "### (Optional) Save Metrics to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_out = 'model_metrics.csv'\n",
    "metrics_table.to_csv(metrics_out, index=False)\n",
    "print(f\"Saved metrics to {metrics_out}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
